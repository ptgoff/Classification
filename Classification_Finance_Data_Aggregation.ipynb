{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-05-06T16:20:07.693406Z",
     "iopub.status.busy": "2021-05-06T16:20:07.693102Z",
     "iopub.status.idle": "2021-05-06T16:20:13.294559Z",
     "shell.execute_reply": "2021-05-06T16:20:13.293663Z",
     "shell.execute_reply.started": "2021-05-06T16:20:07.693336Z"
    }
   },
   "source": [
    "# Resources\n",
    "### Financial Modeling:\n",
    "https://medium.com/nerd-for-tech/all-you-need-to-know-about-yfinance-yahoo-finance-library-fa4c6e48f08e <br>\n",
    "https://levelup.gitconnected.com/how-i-tripled-my-return-on-bitcoin-using-mathematics-algorithms-and-python-347edd9b5625 <br>\n",
    "https://medium.com/analytics-vidhya/python-i-have-tested-a-trading-mathematical-technic-in-realtime-658a80381151 <br>\n",
    "\n",
    "### Text analysis:\n",
    "https://medium.com/@deephavendatalabs/earnings-call-sentiment-analysis-part-i-e3e7aafe2cab <br>\n",
    "https://codingandfun.com/analysing-company-earning-calls-with-python/ <br>\n",
    "https://codingandfun.com/company-earnings-sentiment-analysis-with-python/ <br>\n",
    "https://ourcodingclub.github.io/tutorials/topic-modelling-python/ <br>\n",
    "https://towardsdatascience.com/natural-language-processing-feature-engineering-using-tf-idf-e8b9d00e7e76 <br>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## <font color='yellow'> Data Import and Aggregation  </font>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-05-12T23:04:49.016488Z",
     "iopub.status.busy": "2021-05-12T23:04:49.015909Z",
     "iopub.status.idle": "2021-05-12T23:04:49.021160Z",
     "shell.execute_reply": "2021-05-12T23:04:49.019763Z",
     "shell.execute_reply.started": "2021-05-12T23:04:49.016430Z"
    }
   },
   "outputs": [],
   "source": [
    "import yfinance as yf\n",
    "from datetime import datetime\n",
    "from datetime import date\n",
    "from datetime import timedelta\n",
    "import numpy as np\n",
    "import os\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-05-13T14:08:21.212639Z",
     "iopub.status.busy": "2021-05-13T14:08:21.212085Z",
     "iopub.status.idle": "2021-05-13T14:08:21.225100Z",
     "shell.execute_reply": "2021-05-13T14:08:21.224342Z",
     "shell.execute_reply.started": "2021-05-13T14:08:21.212585Z"
    }
   },
   "outputs": [],
   "source": [
    "# Quarterly call transcripts are saved in \"directory\"\n",
    "directory = r'/Users/pgoff/Google Drive/1_Learning_Python/Goff_Repo/Classification/tech_transcripts'\n",
    "transcripts = [trans for trans in os.listdir(directory) if (trans.find(\".txt\") + 1)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-05-13T15:48:26.844871Z",
     "iopub.status.busy": "2021-05-13T15:48:26.844627Z",
     "iopub.status.idle": "2021-05-13T15:48:26.865395Z",
     "shell.execute_reply": "2021-05-13T15:48:26.864331Z",
     "shell.execute_reply.started": "2021-05-13T15:48:26.844844Z"
    }
   },
   "outputs": [],
   "source": [
    "# Iterate over all stock tickers:\n",
    "tech_tickers = [\"STX\" ,\"HPE\" ,\"TER\" ,\"QRVO\" ,\"UMC\" ,\"APH\" ,\"BR\" ,\"TRMB\" ,\"STNE\" ,\"SPLK\" ,\"PAYC\" ,\"LOGI\" ,\"SSNC\",\n",
    "                \"AKAM\" ,\"NTAP\" ,\"COUP\" ,\"CHKP\" ,\"CLVT\" ,\"UI\" ,\"TYL\" ,\"LYFT\" ,\"ZEN\" ,\"TDY\" ,\"WIX\" ,\"ON\" ,\"PTC\" ,\"NUAN\" ,\"MPWR\" ,\"ENTG\" ,\"CTXS\" ,\"LDOS\" ,\"ASX\" ,\n",
    "                \"NICE\" ,\"FICO\" ,\"CGNX\" ,\"PAGS\" ,\"GDDY\" ,\"AFRM\" ,\"BSY\" ,\"CDAY\" ,\"OTEX\" ,\"NLOK\" ,\"JKHY\" ,\"BKI\" ,\"FFIV\" ,\"TUYA\" ,\"SEDG\" ,\"BILL\" ,\"IPGP\" ,\"AVLR\" ,\n",
    "                \"CREE\" ,\"OLED\" ,\"DBX\" ,\"DOX\" ,\"MKSI\" ,\"DLB\" ,\"PSFE\" ,\"PFPT\" ,\"MCFE\" ,\"PEGA\" ,\"ESTC\" ,\"PCTY\" ,\"RUN\" ,\"FLEX\" ,\"ST\" ,\"KC\" ,\"JNPR\" ,\"G\" ,\"WEX\" ,\n",
    "                \"AZPN\" ,\"DXC\" ,\"ARW\" ,\"GLOB\" ,\"MANH\" ,\"TIXT\" ,\"GWRE\" ,\"CIEN\" ,\"JBL\" ,\"FSLR\" ,\"FLIR\" ,\"PLAN\" ,\"LPL\" ,\"LSPD\" ,\"EEFT\" ,\"BRKS\" ,\"COMP\" ,\"LSCC\" ,\n",
    "                \"FOUR\" ,\"SMAR\" ,\"CDK\" ,\"CACI\" ,\"LAZR\" ,\"LFUS\" ,\"IIVI\" ,\"SNX\" ,\"COHR\" ,\"LITE\" ,\"NCR\" ,\"BMBL\" ,\"BL\" ,\"MSTR\" ,\"SLAB\" ,\"CLGX\" ,\"NTNX\" ,\"VNT\" ,\"DAVA\" ,\n",
    "                \"OCFT\" ,\"CRCT\" ,\"AI\" ,\"NATI\" ,\"TDC\" ,\"JCOM\" ,\"NCNO\" ,\"DSGX\" ,\"AYX\" ,\"SAIC\" ,\"ACVA\" ,\"DQ\" ,\"QTWO\" ,\"PSTG\" , \"POWI\" ,\"RXT\" ,\"XRX\" ,\n",
    "                \"AMKR\" ,\"FSLY\" ,\"ALTR\" ,\"DOCN\" ,\"PRSP\" ,\"ALGM\" ,\"TTEC\" ,\"SYNA\" ,\"CCMP\" ,\"BB\" ,\"ASAN\" ,\"SONO\" ,\"CYBR\" ,\"FEYE\" ,\"NOVT\" ,\"CRUS\" ,\"ACIW\" ,\"AVT\" ,\"SWCH\" ,\n",
    "                \"OLO\" ,\"ATC\" ,\"SAIL\" ,\"WK\" ,\"ALRM\" ,\"SMTC\" ,\"MDLA\" ,\"SABR\" ,\"MSP\" ,\"SPWR\" ,\"FROG\" ,\"QLYS\" ,\"TENB\" ,\"ENV\" ,\"JAMF\" ,\"NEWR\" ,\"DIOD\" ,\"VICR\" ,\n",
    "                \"MTSI\" ,\"VIAV\" ,\"ROG\" ,\"STMP\" ,\"SPSC\" ,\"VSH\" ,\"CLDR\" ,\"VSAT\" ,\"COMM\" ,\"ITRI\" ,\"MANT\" ,\"LPSN\" ,\"NSIT\" ,\"CRNC\" ,\"EXLS\" ,\"VNET\" ,\"BOX\" ,\"BLKB\" ,\"VRNT\" ,\n",
    "                \"RAMP\" ,\"AMBA\" ,\"FN\" ,\"CVLT\" ,\"EGHT\" ,\"ONTO\" ,\"NOVA\", \"EVTC\" ,\"CRSR\" ,\"KLIC\" ,\"FORM\" ,\"TSEM\" ,\"ESE\" ,\"YALA\" ,\"CALX\" ,\"IRBT\" ,\"MIME\" ,\n",
    "                \"CSOD\" ,\"SANM\" ,\"PLXS\" ,\"NVMI\" ,\"MXL\",\n",
    "               \"SVMK\" ,\"CSIQ\" ,\"DDD\" ,\"SIMO\" ,\"PRFT\" ,\"MFGP\" ,\"AVYA\" ,\"SEMR\" ,\"BTRS\" ,\"RMBS\" ,\"HIMX\" ,\n",
    "                \"XPER\" ,\"MVIS\" ,\"PING\" ,\"UCTT\" ,\"PRGS\" ,\"NTCT\" ,\"KN\" ,\"EB\" ,\"MAXR\" ,\"ZUO\" ,\"SMCI\" ,\"ONTF\" ,\"PRO\" ,\"OUST\" ,\"MEI\" ,\"OSIS\" ,\"EPAY\" ,\n",
    "                \"SYKE\" ,\"SUMO\" ,\"INFN\" ,\"RAAS\" ,\"PAR\" ,\"PLT\" ,\"TTMI\" ,\"YEXT\" ,\"DCBO\" ,\"COHU\" ,\"SPNS\" ,\"GPRO\" ,\"CNDT\" ,\"UIS\" ,\"ICHR\" ,\"VRNS\" ,\"CSGS\" ,\"JKS\" ,\n",
    "                \"MTLS\" ,\"EXTR\" ,\"FORTY\" ,\"QADA\" ,\"PLUS\" ,\"ACLS\" ,\"MODN\" ,\"QADB\" ,\"MLAB\" ,\"CNXN\" ,\"RDWR\" ,\"LINX\" ,\"FARO\" ,\"OPRA\" ,\"AGYS\" ,\"GSKY\" ,\"DBD\" ,\"VCRA\" ,\"NTGR\" ,\n",
    "                \"CEVA\" ,\"PI\" ,\"SGH\" ,\"BHE\" ,\"SSYS\" ,\"VECO\" ,\"IMOS\" ,\"SCWX\" ,\"CLS\" ,\"CTS\" ,\"AUDC\" ,\"LASR\" ,\"IIIV\" ,\"EBIX\" ,\"MX\" ,\"ADTN\" ,\"PLAB\" ,\"UEIC\" ,\"SCSC\" ,\"INSG\" ,\n",
    "                \"MGIC\" ,\"AOSL\" ,\"HLIT\" ,\"ATEN\" ,\"CASA\" ,\"PDFS\" ,\"ABST\" ,\"ECOM\" ,\"ZEPP\" ,\"AMSWA\" ,\"ALLT\" ,\"CMTL\" ,\"BCOV\" ,\"ITRN\" ,\"MAXN\" ,\"GILT\" ,\"SWIR\" ,\"DGII\" ,\n",
    "                \"VIOT\" ,\"DMRC\" ,\"HCKT\" ,\"SOL\" ,\"EBON\" ,\"NPTN\" ,\"ETWO\" ,\"CAMP\" ,\"VPG\" ,\"VOXX\" ,\"ZIXI\" ,\"AXTI\" ,\"LLNW\" ,\"DSPG\" ,\"VIAO\" ,\"VHC\" ,\"TUFN\" ,\"HBB\" ,\"SILC\" ,\n",
    "                \"UEPS\" ,\"DAKT\" ,\"CMCM\" ,\"MIXT\" ,\"WTRH\" ,\"CRNT\" ,\"SOS\" ,\"KVHI\" ,\"IMMR\" ,\"BELFA\" ,\"BELFB\" ,\"EXFO\" ,\"LYTS\" ,\"CIH\" ,\"OIIM\" ,\"SQNS\" ,\"AVNW\" ,\"CTG\" ,\"GSIT\" ,\n",
    "                \"ASYS\" ,\"SREV\" ,\"SNCR\" ,\"SPI\" ,\"CTK\" ,\"PCTI\" ,\"RELL\" ,\"RCAT\" ,\"TESS\" ,\"UTSI\" ,\"MINDP\" ,\"SEAC\" ,\"MIND\" ,\"KNBE\" ,\"SABRP\" ,\"IIVIP\" ,\"VZIO\" ,\"CTLP\" ,\n",
    "                \"COIN\" ,\"AVGOP\" ,\"ALKT\" ,\"PATH\" , \n",
    "                \"AAPL\" ,\"MSFT\" ,\"TSM\" ,\"NVDA\" ,\"ASML\" ,\"ORCL\" ,\"INTC\" ,\"ADBE\" ,\"CSCO\" ,\"CRM\" ,\"ACN\" ,\"AVGO\" ,\"TXN\" ,\"SAP\" ,\"QCOM\" ,\"SHOP\" ,\"IBM\" ,\"SONY\" ,\"AMAT\" ,\n",
    "                \"INTU\" ,\"SQ\" ,\"NOW\" ,\"MU\" ,\"AMD\" ,\"FIS\" ,\"LRCX\" ,\"UBER\" ,\"FISV\" ,\"INFY\" ,\"DELL\" ,\"VMW\" ,\"ADSK\" ,\"ADI\" ,\"WDAY\" ,\"TEAM\" ,\n",
    "                \"ERIC\" ,\"HPQ\" ,\"TEL\" ,\"CRWD\" ,\"CTSH\" ,\"MCHP\" ,\"PLTR\" ,\"WIT\" ,\"DOCU\" ,\"SNPS\" ,\"CDNS\" ,\"GLW\" ,\"FTNT\" ,\"STM\" ,\"PANW\" ,\"MSI\" ,\"MRVL\" ,\"OKTA\" ,\"XLNX\" ,\n",
    "                \"SWKS\" ,\"ANSS\" ,\"NOK\" ,\"GRMN\" ,\"KEYS\" ,\"FTV-PA\" ,\"EPAM\" ,\"MXIM\" ,\"VRSN\" ,\"ZBRA\" ,\"ANET\" ,\"CDW\" ,\"FTV\" ,\"CAJ\" ,\"WORK\" ,\"FLT\" ,\"RNG\" ,\"GIB\" ,\n",
    "                \"HUBS\" ,\"ZS\" ,\"DDOG\"]\n",
    "# Removed \"NXPI\", \"KLAC\", \"CNXC\", \"SWI\", \"CD\", \"DCT\", \"API\", \"PD\", \"BAND\" ,\"DM\" , \"SATS\", \"RIOT\", \"VLDR\", \"GB\", \"DSP\", \"CGNT\", \"APP\", \"STEM\", \"DV\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-05-13T15:48:54.020819Z",
     "iopub.status.busy": "2021-05-13T15:48:54.020590Z",
     "iopub.status.idle": "2021-05-13T18:48:48.267813Z",
     "shell.execute_reply": "2021-05-13T18:48:48.266985Z",
     "shell.execute_reply.started": "2021-05-13T15:48:54.020794Z"
    }
   },
   "outputs": [],
   "source": [
    "df = pd.DataFrame()\n",
    "i=0\n",
    "\n",
    "for tick in tech_tickers:\n",
    "    pre_post = pd.DataFrame()\n",
    "    i+=1\n",
    "    # Selecting only transcripts that correspond to a given ticker:\n",
    "    subset_transcripts = [trans for trans in transcripts if (trans.find(tick.lower()) + 1)]\n",
    "\n",
    "    # Iterating over each text file for a given stock to:\n",
    "        # (a) Create the dataframe\n",
    "        # (b) Collect the stock data prior to and after the call\n",
    "    for file in subset_transcripts:\n",
    "        # Extracting the quarter from the file name\n",
    "        call_quarter = file[file.find(\"q\")+1:file.find(\"q\")+2]\n",
    "        \n",
    "        # Extracting the call date from the file name\n",
    "        call_date = file[file.find(\"_2\")+1:-4]\n",
    "        call_date = date(year=int(call_date[0:4]), month=int(call_date[4:6]), day=int(call_date[6:8]))\n",
    "\n",
    "        # Using yfinance to bring in finance data\n",
    "        tick_obj = yf.Ticker(tick.upper())\n",
    "\n",
    "        # Collecting data from before the call (selecting a 14 day window to ensure 7 days across holidays and weekends)\n",
    "        week_prior = call_date - timedelta(days=14)\n",
    "        week_prior = datetime.strftime(week_prior, '%Y-%m-%d') \n",
    "        end_day = datetime.strftime(call_date, '%Y-%m-%d') \n",
    "        \n",
    "        if tick_obj.history(start=week_prior, end=end_day, interval='1d')[-7:].shape[0] > 0:\n",
    "\n",
    "            pre = tick_obj.history(start=week_prior, end=end_day, interval='1d')[-7:]\n",
    "            pre['tick']=tick\n",
    "            \n",
    "            # Slope of open prices prior to call:\n",
    "            df_reg = pre.copy(deep=True)\n",
    "            df_reg['DATE'] = pd.to_datetime(pre.index, format='%Y-%m-%d')\n",
    "            df_reg['day'] = df_reg['DATE'].dt.day\n",
    "            df_reg['int'] = 1\n",
    "            pre = pre.groupby(pre['tick']).mean()\n",
    "            \n",
    "            if df_reg[['day', 'int']].shape[0] > 1: # Avoiding singular matricies\n",
    "                pre['slope_pre'] = np.linalg.inv(df_reg[['day', 'int']].T.dot(df_reg[['day', 'int']])).dot(df_reg[['day', 'int']].T.dot(df_reg['Open']))[0]\n",
    "\n",
    "            # Collecting data from after the call\n",
    "            week_after = call_date + timedelta(days=14)\n",
    "            week_after = datetime.strftime(week_after, '%Y-%m-%d') \n",
    "            call_day = call_date + timedelta(days=1)\n",
    "            call_day = datetime.strftime(call_day, '%Y-%m-%d') \n",
    "\n",
    "            post = tick_obj.history(start=call_day, end=week_after, interval='1d')[:7]\n",
    "            post['tick']=tick\n",
    "            post = post.groupby(post['tick'], as_index=False).mean()\n",
    "            post = post.merge(pre, on='tick', suffixes=['_post', '_pre'])\n",
    "            post['date']=call_date\n",
    "            post['call_q'] = call_quarter\n",
    "            post['id'] = file[:-4]\n",
    "            pre_post = pre_post.append(post, ignore_index=True)        \n",
    "\n",
    "        df = df.append(pre_post, ignore_index=True)\n",
    "    print(f'Ticker: {tick} finished at {datetime.now().strftime(\"%H:%M:%S\")}. Obs = {len(pre_post)}. {i} of {len(tech_tickers)}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-05-13T18:56:40.671227Z",
     "iopub.status.busy": "2021-05-13T18:56:40.670971Z",
     "iopub.status.idle": "2021-05-13T18:56:40.786957Z",
     "shell.execute_reply": "2021-05-13T18:56:40.785908Z",
     "shell.execute_reply.started": "2021-05-13T18:56:40.671199Z"
    }
   },
   "outputs": [],
   "source": [
    "df = df.drop_duplicates()\n",
    "df.to_pickle(\"./tech_tickers.pkl\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-05-13T18:56:50.590182Z",
     "iopub.status.busy": "2021-05-13T18:56:50.589954Z",
     "iopub.status.idle": "2021-05-13T18:56:50.634859Z",
     "shell.execute_reply": "2021-05-13T18:56:50.634256Z",
     "shell.execute_reply.started": "2021-05-13T18:56:50.590158Z"
    }
   },
   "outputs": [],
   "source": [
    "# Quarterly call transcripts are saved in \"directory\"\n",
    "directory = r'/Users/pgoff/Google Drive/1_Learning_Python/Goff_Repo/Classification/health_transcripts'\n",
    "transcripts = [trans for trans in os.listdir(directory) if (trans.find(\".txt\") + 1)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-05-13T18:56:55.720303Z",
     "iopub.status.busy": "2021-05-13T18:56:55.720047Z",
     "iopub.status.idle": "2021-05-13T18:56:55.736681Z",
     "shell.execute_reply": "2021-05-13T18:56:55.735509Z",
     "shell.execute_reply.started": "2021-05-13T18:56:55.720281Z"
    }
   },
   "outputs": [],
   "source": [
    "health_tickers = [\"GILD\" ,\"ZTS\" ,\"HCA\" ,\"BDX\" ,\"MRNA\" ,\"BSX\" ,\"HUM\" ,\n",
    "                  \"EW\" ,\"VRTX\" ,\"ILMN\" ,\"REGN\" ,\"TAK\" ,\"PHG\" ,\"WBA\" ,\"ALGN\" ,\"IDXX\" ,\"BAX\" ,\n",
    "                  \"IQV\" ,\"BIIB\" ,\"BNTX\" ,\"VEEV\" ,\"CNC\" ,\"ALXN\" ,\"ZBH\" ,\"DXCM\" ,\"ALC\" ,\n",
    "                  \"MTD\" ,\"MCK\" ,\"BGNE\" ,\"RMD\" ,\"LH\" ,\"RPRX\" ,\"SGEN\" ,\"GMAB\" ,\"WST\" ,\"ABC\" ,\n",
    "                  \"CERN\" ,\"FMS\" ,\"TDOC\" ,\"COO\" ,\"HZNP\" ,\"NVCR\" ,\"WAT\" ,\"TFX\" ,\"SNN\" ,\"BIO-B\" ,\n",
    "                  \"DGX\" ,\"INCY\" ,\"CTLT\" ,\"BIO\" ,\"STE\" ,\"GRFS\" ,\"VTRS\" ,\"HOLX\" ,\"CRL\" ,\"PODD\" ,\n",
    "                  \"CAH\" ,\"PPD\" ,\"TECH\" ,\"MOH\" ,\"TXG\" ,\"ALNY\" ,\"PKI\" ,\"XRAY\" ,\"ELAN\" ,\"BMRN\" ,\n",
    "                  \"GDRX\" ,\"OSH\" ,\"DVA\" ,\"GH\" ,\"ABMD\" ,\"ARGX\" ,\"UHS\" ,\"MASI\" ,\"ICLR\" ,\"RDY\" ,\n",
    "                  \"NVAX\" ,\"TEVA\" ,\"HSIC\" ,\"PRAH\" ,\"QGEN\" ,\"BRKR\" ,\"RGEN\" ,\"PEN\" ,\"BHC\" ,\"JAZZ\" ,\n",
    "                  \"MRVI\" ,\"CGC\" ,\"UTHR\" ,\"EHC\" ,\"SYNH\" ,\"NBIX\" ,\"AMED\" ,\"NTRA\" ,\"RARE\" ,\"ABCL\" ,\n",
    "                  \"CHE\" ,\"MRTX\" ,\"BBIO\" ,\"EXEL\" ,\"HRC\" ,\"GMED\" ,\"NVST\" ,\"ASND\" ,\"CHNG\" ,\"THC\" ,\n",
    "                  \"ARWR\" ,\"SHC\" ,\"DNLI\" ,\"HALO\" ,\"RCM\" ,\"LHCG\" ,\"IART\" ,\"IBRX\" ,\"OMCL\" ,\"SRPT\" ,\n",
    "                  \"MEDP\" ,\"PRGO\" ,\"ACHC\" ,\"SGFY\" ,\"HQY\" ,\"NVTA\" ,\"ONEM\" ,\"NVRO\" ,\"SEM\" ,\n",
    "                  \"IONS\" ,\"ALLK\" ,\"BPMC\" ,\"INSP\" ,\"TWST\" ,\"NEOG\" ,\"ADPT\" ,\"SWAV\" ,\"GLPG\" ,\"ALHC\" ,\n",
    "                  \"APHA\" ,\"INOV\" ,\"MPLN\" ,\"OCDX\" ,\"PACB\" ,\"NARI\" ,\"SDGR\" ,\"ABCM\" ,\"ENSG\" ,\"OSCR\" ,\n",
    "                  \"QDEL\" ,\"PGNY\" ,\"CERT\" ,\"ICUI\" ,\"PINC\" ,\"BHVN\" ,\"AMN\" ,\"BEAM\" ,\"ALLO\" ,\"CVET\" ,\n",
    "                  \"CNMD\" ,\"LIVN\" ,\"HCM\" ,\"AGIO\" ,\"CMD\" ,\"GKOS\" ,\"APLS\" ,\"ARNA\" ,\"MMSI\" ,\n",
    "                  \"LEGN\" ,\"NUVA\" ,\"PDCO\" ,\"ALKS\" ,\"SWTX\" ,\"ACAD\" ,\"NKTR\" ,\"INSM\" ,\"EBS\" ,\n",
    "                  \"AMWL\" ,\"SDC\" ,\"OPCH\" ,\"HAE\" ,\"TPTX\" ,\"SANA\" ,\"ITGR\" ,\"BLI\" ,\"SGRY\" ,\"ARVN\" ,\n",
    "                  \"MOR\" ,\"INMD\" ,\"TARO\" ,\"PTCT\" ,\"PCRX\" ,\"OPK\" ,\"ITCI\" ,\"BFLY\" ,\"TIL\" ,\"MDRX\" ,\n",
    "                  \"OMI\" ,\"SEER\" ,\"MGLN\" ,\"GBT\" ,\"PBH\" ,\"ALXO\" ,\"MD\" ,\"ACCD\" ,\"BCRX\" ,\"TLRY\" ,\n",
    "                  \"AXNX\" ,\"HCSG\" ,\"HCAT\" ,\"OM\" ,\"IRTC\" ,\"EDIT\" ,\"PHR\" ,\"RVMD\" ,\"AVNS\" ,\"RUBY\" ,\n",
    "                  \"MYGN\" ,\"MCRB\" ,\"DRNA\" ,\"MODV\" ,\"DCPH\" ,\"NGM\" ,\"BLUE\" ,\"MDGL\" ,\"RCUS\" ,\"CCXI\" ,\n",
    "                  \"PRLD\" ,\"FGEN\" ,\"IGMS\" ,\"AVIR\" ,\"MGNX\" ,\"GBIO\" ,\"MYOV\" ,\"SILK\" ,\"ADCT\" ,\"LMNX\" ,\n",
    "                  \"IRWD\" ,\"IMCR\" ,\"CYH\" ,\"EVH\" ,\"ACB\" ,\"CYTK\" ,\"KURA\" ,\"REPL\" ,\"IMVT\" ,\"ARQT\" ,\n",
    "                  \"PMVP\" ,\"CSII\" ,\"AMTI\" ,\"DSGN\" ,\"USPH\" ,\"LUNG\" ,\"ADUS\" ,\"SGMO\" ,\"RGNX\" ,\"QURE\" ,\"NFH\" ,\n",
    "                  \"INGN\" ,\"EWTX\" ,\"CCCC\" ,\"KRON\" ,\"ALVR\" ,\"IMGN\" ,\"PGEN\" ,\"ZYME\" ,\"ALEC\" ,\"STTK\" ,\n",
    "                  \"INO\" ,\"ZEAL\" ,\"CDXS\" ,\"PETQ\" ,\"CGEM\" ,\"ENDP\" ,\"CRY\" ,\"CMPS\" ,\"NXGN\" ,\"NRC\" ,\"BKD\" ,\n",
    "                  \"ACRS\" ,\"ATEC\" ,\"TVTY\" ,\"RPTX\" ,\"INVA\" ,\"YMAB\" ,\"STOK\" ,\"PLRX\" ,\"ATRI\" ,\"PNTG\" ,\"CRTX\" ,\n",
    "                  \"SNDL\" ,\"ATRA\" ,\"PRAX\" ,\"ALGS\" ,\"KNTE\" ,\"ENTA\" ,\"MRSN\" ,\"CNST\" ,\"SRRK\" ,\"KNSA\" ,\"HNGR\" ,\n",
    "                  \"RAD\" ,\"APR\" ,\"VREX\" ,\"PHAT\" ,\"PRTA\" ,\"BDTX\" ,\"AKRO\" ,\"ANGO\" ,\"FDMT\" ,\"PCVX\" ,\n",
    "                  \"VOR\" ,\"PASG\" ,\"NTUS\" ,\"AMPH\" ,\"AMRX\" ,\"ORIC\" ,\"OLMA\" ,\"OFIX\" ,\"NKTX\" ,\"HEXO\" ,\"HSTM\" ,\n",
    "                  \"VIVO\" ,\"TSHA\" ,\"BOLT\" ,\"PHVS\" ,\"BVS\" ,\"MESO\" ,\"TCRR\" ,\"GRCL\" ,\"COLL\" ,\"ADAP\" ,\n",
    "                  \"ANNX\" ,\"SRDX\" ,\"GTHX\" ,\"RFL\" ,\"VYNE\" ,\"KDNY\" ,\"SNDX\" ,\"HARP\" ,\"ANAB\" ,\"OSUR\" ,\n",
    "                  \"EPZM\" ,\"CALT\" ,\"BCYC\" ,\"ATHA\" ,\"DBVT\" ,\"ACHL\" ,\"ZIOP\" ,\"ORTX\" ,\"GOSS\" ,\"LXRX\" ,\n",
    "                  \"ISEE\" ,\"KDMN\" ,\"CO\" ,\"PETS\" ,\"FNCH\" ,\"IDYA\" ,\"SPNE\" ,\"RLMD\" ,\"KPTI\" ,\"GTS\" ,\"CLVS\" ,\n",
    "                  \"MGTX\" ,\"TARS\" ,\"ANIK\" ,\"TLMD\" ,\"OGI\" ,\"ICPT\" ,\"RIGL\" ,\"CRNX\" ,\"CUTR\" ,\"PSTX\" ,\"CTMX\" ,\n",
    "                  \"XBIT\" ,\"NBTX\" ,\"EVLO\" ,\"VAPO\" ,\"DTIL\" ,\"OYST\" ,\"HOOK\" ,\"AKUS\" ,\"ANGN\" ,\"CPSI\" ,\"PRVB\" ,\n",
    "                  \"SPPI\" ,\"MTEM\" ,\"AMYT\" ,\"ARAY\" ,\"GERN\" ,\"SGTX\" ,\"ATNX\" ,\"GRTS\" ,\"VIRX\" ,\"SLDB\" ,\"SIEN\" ,\n",
    "                  \"TERN\" ,\"PBYI\" ,\"INZY\" ,\"OPT\" ,\"TXMD\" ,\"FUSN\" ,\"AVRO\" ,\"SPRB\" ,\"BCEL\" ,\"SPRO\" ,\"FREQ\" ,\n",
    "                  \"FLDM\" ,\"AFIB\" ,\"BDSI\" ,\"APYX\" ,\"UTMD\" ,\"JNCE\" ,\"ORPH\" ,\"SYRS\" ,\"FRLN\" ,\"KLDO\" ,\n",
    "                  \"LVTX\" ,\"KALA\" ,\"BLU\" ,\"SQZ\" ,\"CSLT\" ,\"FIXX\" ,\"KMDA\" ,\"CBAY\" ,\"NH\" ,\"IVC\" ,\"AUTL\" ,\n",
    "                  \"KZR\" ,\"IMUX\" ,\"UBX\" ,\"ABUS\" ,\"CHMA\" ,\"CABA\" ,\"OVID\" ,\"NXTC\" ,\"NUVB\" ,\"TCDA\" ,\"LHDX\" ,\"INFI\" ,\n",
    "                  \"OSMT\" ,\"LCI\" ,\"SRGA\" ,\"NCNA\" ,\"DBTX\" ,\"GNFT\" ,\"OBSV\" ,\"XERS\" ,\"MIST\" ,\"VYGR\" ,\"OPTN\" ,\n",
    "                  \"SBBP\" ,\"SCPH\" ,\"ERYP\" ,\"CCM\" ,\"CALA\" ,\"SIOX\" ,\"GLTO\" ,\"ENZ\" ,\"ASMB\" ,\"IMRA\" ,\"ODT\" ,\"OTIC\" ,\n",
    "                  \"IFRX\" ,\"CSU\" ,\"APRE\" ,\"SVRA\" ,\"APTX\" ,\"CYCN\" ,\"ARAV\" ,\"ECOR\" ,\"GEG\" ,\"TRIB\" ,\"ALNA\" ,\n",
    "                  \"ACOR\" ,\"CPIX\" ,\"NBRV\" ,\"TLGT\" ,\"PTIX\" ,\"AGTI\" ,\"HOWL\" ,\"AVAH\" ,\"VACC\" ,\"BDXB\" ,\"AKYA\" ,\n",
    "                  \"CHNGU\" ,\"PALI\" ,\"AGL\" ,\"DHR-PB\" ,\"BSX-PA\" ,\"BMEA\" ,\"RAIN\" ,\"TMCI\" ,\"RXRX\" ,\"ELAT\" ,\"NUWE\" ,\"VECT\" ,\"PRVA\",\n",
    "                 \"JNJ\" ,\"UNH\" ,\"PFE\" ,\"ABT\" ,\"ABBV\" ,\"NVS\" ,\"MRK\" ,\"TMO\" ,\"LLY\", \"MDT\" ,\"NVO\" ,\"DHR-PA\" ,\"AMGN\" ,\"BMY\" ,\"AZN\" ,\"SNY\" ,\"CVS\" ,\"ISRG\" ,\"ANTM\" ,\n",
    "                  \"SYK\" ,\"GSK\"]\n",
    "# removed: \"DHR\", \"CI\" , \"A\", \"VIR\", INNV\", \"CLOV\", \"EAR\", \"TBIO\", \"DYN\", \"RXDX\", \"IPHA\", \"COGT\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-05-13T18:57:37.833827Z",
     "iopub.status.busy": "2021-05-13T18:57:37.833599Z",
     "iopub.status.idle": "2021-05-13T21:10:59.221420Z",
     "shell.execute_reply": "2021-05-13T21:10:59.220662Z",
     "shell.execute_reply.started": "2021-05-13T18:57:37.833803Z"
    }
   },
   "outputs": [],
   "source": [
    "df = pd.DataFrame()\n",
    "i=0\n",
    "\n",
    "for tick in health_tickers:\n",
    "    pre_post= pd.DataFrame()\n",
    "    i+=1\n",
    "    # Selecting only transcripts that correspond to a given ticker:\n",
    "    subset_transcripts = [trans for trans in transcripts if (trans.find(tick.lower()) + 1)]\n",
    "\n",
    "    # Iterating over each text file for a given stock to:\n",
    "        # (a) Create the dataframe\n",
    "        # (b) Collect the stock data prior to and after the call\n",
    "    for file in subset_transcripts:\n",
    "        # Extracting the quarter from the file name\n",
    "        call_quarter = file[file.find(\"q\")+1:file.find(\"q\")+2]\n",
    "        \n",
    "        # Extracting the call date from the file name\n",
    "        call_date = file[file.find(\"_2\")+1:-4]\n",
    "        call_date = date(year=int(call_date[0:4]), month=int(call_date[4:6]), day=int(call_date[6:8]))\n",
    "\n",
    "        # Using yfinance to bring in finance data\n",
    "        tick_obj = yf.Ticker(tick.upper())\n",
    "\n",
    "        # Collecting data from before the call (selecting a 14 day window to ensure 7 days across holidays and weekends)\n",
    "        week_prior = call_date - timedelta(days=14)\n",
    "        week_prior = datetime.strftime(week_prior, '%Y-%m-%d') \n",
    "        end_day = datetime.strftime(call_date, '%Y-%m-%d') \n",
    "        \n",
    "        if tick_obj.history(start=week_prior, end=end_day, interval='1d')[-7:].shape[0] > 0:\n",
    "\n",
    "            pre = tick_obj.history(start=week_prior, end=end_day, interval='1d')[-7:]\n",
    "            pre['tick']=tick\n",
    "            \n",
    "            # Slope of open prices prior to call:\n",
    "            df_reg = pre.copy(deep=True)\n",
    "            df_reg['DATE'] = pd.to_datetime(pre.index, format='%Y-%m-%d')\n",
    "            df_reg['day'] = df_reg['DATE'].dt.day\n",
    "            df_reg['int'] = 1\n",
    "            pre = pre.groupby(pre['tick']).mean()\n",
    "            \n",
    "            if df_reg[['day', 'int']].shape[0] > 1: # Avoiding singular matricies\n",
    "                pre['slope_pre'] = np.linalg.inv(df_reg[['day', 'int']].T.dot(df_reg[['day', 'int']])).dot(df_reg[['day', 'int']].T.dot(df_reg['Open']))[0]\n",
    "\n",
    "            # Collecting data from after the call\n",
    "            week_after = call_date + timedelta(days=14)\n",
    "            week_after = datetime.strftime(week_after, '%Y-%m-%d') \n",
    "            call_day = call_date + timedelta(days=1)\n",
    "            call_day = datetime.strftime(call_day, '%Y-%m-%d') \n",
    "\n",
    "            post = tick_obj.history(start=call_day, end=week_after, interval='1d')[:7]\n",
    "            post['tick']=tick\n",
    "            post = post.groupby(post['tick'], as_index=False).mean()\n",
    "            post = post.merge(pre, on='tick', suffixes=['_post', '_pre'])\n",
    "            post['date']=call_date\n",
    "            post['call_q'] = call_quarter\n",
    "            post['id'] = file[:-4]\n",
    "            pre_post = pre_post.append(post, ignore_index=True)        \n",
    "\n",
    "        df = df.append(pre_post, ignore_index=True)\n",
    "    print(f'Ticker: {tick} finished at {datetime.now().strftime(\"%H:%M:%S\")}. Obs = {len(pre_post)}. {i} of {len(health_tickers)}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-05-13T21:43:43.292492Z",
     "iopub.status.busy": "2021-05-13T21:43:43.292239Z",
     "iopub.status.idle": "2021-05-13T21:43:43.331316Z",
     "shell.execute_reply": "2021-05-13T21:43:43.330223Z",
     "shell.execute_reply.started": "2021-05-13T21:43:43.292463Z"
    }
   },
   "outputs": [],
   "source": [
    "df = df.drop_duplicates()\n",
    "df.to_pickle(\"./health_tickers.pkl\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-05-13T21:43:49.380600Z",
     "iopub.status.busy": "2021-05-13T21:43:49.380361Z",
     "iopub.status.idle": "2021-05-13T21:43:49.410226Z",
     "shell.execute_reply": "2021-05-13T21:43:49.409623Z",
     "shell.execute_reply.started": "2021-05-13T21:43:49.380573Z"
    }
   },
   "outputs": [],
   "source": [
    "# Quarterly call transcripts are saved in \"directory\"\n",
    "directory = r'/Users/pgoff/Google Drive/1_Learning_Python/Goff_Repo/Classification/energy_transcripts'\n",
    "transcripts = [trans for trans in os.listdir(directory) if (trans.find(\".txt\") + 1)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-05-13T22:20:46.529992Z",
     "iopub.status.busy": "2021-05-13T22:20:46.529686Z",
     "iopub.status.idle": "2021-05-13T22:20:46.543063Z",
     "shell.execute_reply": "2021-05-13T22:20:46.542087Z",
     "shell.execute_reply.started": "2021-05-13T22:20:46.529959Z"
    }
   },
   "outputs": [],
   "source": [
    "energy_tickers = [\"XOM\" ,\"CVX\" ,\"RDS-A\" ,\"RDS-B\" ,\"PTR\" ,\"TOT\" ,\"BP\" ,\"ENB\" ,\"SNP\" ,\"COP\" ,\"EQNR\" ,\"PBR-A\" ,\"PBR\" ,\"EPD\" ,\"TRP\" ,\n",
    "                  \"EOG\" ,\"SLB\" ,\"KMI\" ,\"CNQ\" ,\"MPC\" ,\"PSX\" ,\"PXD\" ,\"SU\" ,\"VLO\" ,\"WMB\" ,\"CSAN\" ,\"MPLX\" ,\"HES\" ,\"ET\" ,\"OXY\" ,\n",
    "                  \"EC\" ,\"BKR\" ,\"OKE\" ,\"HAL\" ,\"PBA\" ,\"DVN\" ,\"CVE\" ,\"TS\" ,\"FANG\" ,\"TPL\" ,\"CLR\" ,\"MMP\" ,\"SSL\" ,\"MRO\" ,\"WES\" ,\"TRGP\" ,\n",
    "                  \"APA\" ,\"PSXP\" ,\"CCJ\" ,\"XEC\" ,\"PAA\" ,\"COG\" ,\"OVV\" ,\"NOV\" ,\"SHLX\" ,\"VVV\" ,\"HFC\" ,\"SHI\" ,\"DCP\" ,\"EQT\" ,\"CHX\" ,\"NFG\" ,\n",
    "                  \"CHK\" ,\"AM\" ,\"UGP\" ,\"PDCE\" ,\"FTI\" ,\"SUN\" ,\"ETRN\" ,\"ENBL\" ,\"MTDR\" ,\"SWN\" ,\"HP\" ,\"MGY\" ,\"CNX\" ,\"VNOM\" ,\"RRC\" ,\"DEN\" ,\n",
    "                  \"MUR\" ,\"AR\" ,\"NS-PB\" ,\"WHD\" ,\"ENLC\" ,\"LBRT\" ,\"REGI\" ,\"CPG\" ,\"CVI\" ,\"RIG\" ,\"CEQP\" ,\"BSM\" ,\"HEP\" ,\"INT\" ,\"NS\" ,\"CRC\" ,\n",
    "                  \"SM\" ,\"CLNE\" ,\"PBF\" ,\"DK\" ,\"PAGP\" ,\"DKL\" ,\"EURN\" ,\"RTLR\" ,\"CPE\" ,\"OAS\" ,\"WLL\" ,\"FRO\" ,\"PTEN\" ,\"YPF\" ,\"AROC\" ,\"USAC\" ,\n",
    "                  \"BPMP\" ,\"CLB\" ,\"OII\" ,\"GLOG-PA\" ,\"NBLX\" ,\"CRK\" ,\"TGP\" ,\"ERF\" ,\"DNOW\" ,\"DRQ\" ,\"VET\" ,\"GLNG\" ,\"RES\" ,\"KOS\" ,\"GEL\" ,\n",
    "                  \"XOG\" ,\"PUMP\" ,\"STNG\" ,\"NGL-PB\" ,\"NGL-PC\" ,\"VEI\" ,\"TALO\" ,\"DHT\" ,\"MNRL\" ,\"PBFX\" ,\"GPRK\" ,\"GLOP-PC\" ,\"GLOP-PB\" ,\"MRC\" ,\n",
    "                  \"GLP\" ,\"NEX\" ,\"VTOL\" ,\"FI\" ,\"SLCA\" ,\"BOOM\" ,\"PARR\" ,\"BCEI\" ,\"OMP\" ,\"ARCH\" ,\"CAPL\" ,\"ARLP\" ,\"HLX\" ,\"KRP\" ,\"ESTE\" ,\"LPG\" ,\n",
    "                  \"NBR\" ,\"TRMD\" ,\"TGS\" ,\"FLNG\" ,\"WTTR\" ,\"NVGS\" ,\"PVAC\" ,\"TDW\" ,\"GLOG\" ,\"HMLP\" ,\"SRLP\" ,\"NBR-PA\" ,\"DMLP\" ,\"SBR\" ,\"CLMT\" ,\n",
    "                  \"REX\" ,\"BRY\" ,\"WTI\" ,\"TNK\" ,\"SOI\" ,\"BTU\" ,\"DSSI\" ,\"SGU\" ,\"LPI\" ,\"CEIX\" ,\"TTI\" ,\"NOA\" ,\"HESM\" ,\"OIS\" ,\"PDS\" ,\"TK\" ,\n",
    "                  \"TNP-PD\" ,\"TNP-PE\" ,\"NR\" ,\"TNP-PF\" ,\"NGL\" ,\"BORR\" ,\"AMR\" ,\"SJT\" ,\"NRP\" ,\"VIST\" ,\"OSG\" ,\"RNET\" ,\"TNP\" ,\"PBT\" ,\"NC\" ,\"TUSK\" ,\n",
    "                  \"GLOP\" ,\"SD\" ,\"EGY\" ,\"SLNG\" ,\"EXTN\" ,\"SBOW\" ,\"NGS\" ,\"FTK\" ,\"AMPY\" ,\"GEOS\" ,\"FET\" ,\"SND\" ,\"DLNG\" ,\"KLXE\" ,\"RNGR\" ,\"SMLP\" ,\n",
    "                  \"MMLP\" ,\"DLNG-PB\" ,\"BPT\" ,\"CCLP\" ,\"PRT\" ,\"PHX\" ,\"GIFI\" ,\"MVO\" ,\"NINE\" ,\"VOC\" ,\"CRT\" ,\"NRT\" ,\"DWSN\" ,\"NNA\" ,\"PVL\" ,\"IO\" ,\n",
    "                  \"CELP\" ,\"ICD\" ,\"MARPS\" ,\"MTR\" ,\"DCP-PB\" ,\"TGP-PA\" ,\"NS-PC\" ,\"ALIN-PA\" ,\"ALIN-PE\" ,\"EP-PC\" ,\"GLOP-PA\" ,\"CEQP-P\" ,\"HMLP-PA\" ,\n",
    "                  \"ALIN-PB\" ,\"DCP-PC\" ,\"NS-PA\" ,\"VAL\" ,\"TGP-PB\" ,\"DLNG-PA\" ,\"GLP-PB\" ,\"GLP-PA\" ,\"GMLPP\" ,\"UROY\"]\n",
    "# Removed: \"E\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-05-13T22:20:48.022564Z",
     "iopub.status.busy": "2021-05-13T22:20:48.022258Z",
     "iopub.status.idle": "2021-05-14T00:10:56.449953Z",
     "shell.execute_reply": "2021-05-14T00:10:56.448985Z",
     "shell.execute_reply.started": "2021-05-13T22:20:48.022526Z"
    }
   },
   "outputs": [],
   "source": [
    "df = pd.DataFrame()\n",
    "i=0\n",
    "\n",
    "for tick in energy_tickers:\n",
    "    pre_post= pd.DataFrame()\n",
    "    i+=1\n",
    "    # Selecting only transcripts that correspond to a given ticker:\n",
    "    subset_transcripts = [trans for trans in transcripts if (trans.find(tick.lower()) + 1)]\n",
    "\n",
    "    # Iterating over each text file for a given stock to:\n",
    "        # (a) Create the dataframe\n",
    "        # (b) Collect the stock data prior to and after the call\n",
    "    for file in subset_transcripts:\n",
    "        # Extracting the quarter from the file name\n",
    "        call_quarter = file[file.find(\"q\")+1:file.find(\"q\")+2]\n",
    "        \n",
    "        # Extracting the call date from the file name\n",
    "        call_date = file[file.find(\"_2\")+1:-4]\n",
    "        call_date = date(year=int(call_date[0:4]), month=int(call_date[4:6]), day=int(call_date[6:8]))\n",
    "\n",
    "        # Using yfinance to bring in finance data\n",
    "        tick_obj = yf.Ticker(tick.upper())\n",
    "\n",
    "        # Collecting data from before the call (selecting a 14 day window to ensure 7 days across holidays and weekends)\n",
    "        week_prior = call_date - timedelta(days=14)\n",
    "        week_prior = datetime.strftime(week_prior, '%Y-%m-%d') \n",
    "        end_day = datetime.strftime(call_date, '%Y-%m-%d') \n",
    "        \n",
    "        if tick_obj.history(start=week_prior, end=end_day, interval='1d')[-7:].shape[0] > 0:\n",
    "\n",
    "            pre = tick_obj.history(start=week_prior, end=end_day, interval='1d')[-7:]\n",
    "            pre['tick']=tick\n",
    "            \n",
    "            # Slope of open prices prior to call:\n",
    "            df_reg = pre.copy(deep=True)\n",
    "            df_reg['DATE'] = pd.to_datetime(pre.index, format='%Y-%m-%d')\n",
    "            df_reg['day'] = df_reg['DATE'].dt.day\n",
    "            df_reg['int'] = 1\n",
    "            pre = pre.groupby(pre['tick']).mean()\n",
    "            \n",
    "            if df_reg[['day', 'int']].shape[0] > 1: # Avoiding singular matricies\n",
    "                pre['slope_pre'] = np.linalg.inv(df_reg[['day', 'int']].T.dot(df_reg[['day', 'int']])).dot(df_reg[['day', 'int']].T.dot(df_reg['Open']))[0]\n",
    "\n",
    "            # Collecting data from after the call\n",
    "            week_after = call_date + timedelta(days=14)\n",
    "            week_after = datetime.strftime(week_after, '%Y-%m-%d') \n",
    "            call_day = call_date + timedelta(days=1)\n",
    "            call_day = datetime.strftime(call_day, '%Y-%m-%d') \n",
    "\n",
    "            post = tick_obj.history(start=call_day, end=week_after, interval='1d')[:7]\n",
    "            post['tick']=tick\n",
    "            post = post.groupby(post['tick'], as_index=False).mean()\n",
    "            post = post.merge(pre, on='tick', suffixes=['_post', '_pre'])\n",
    "            post['date']=call_date\n",
    "            post['call_q'] = call_quarter\n",
    "            post['id'] = file[:-4]\n",
    "            pre_post = pre_post.append(post, ignore_index=True)        \n",
    "\n",
    "    df = df.append(pre_post, ignore_index=True)\n",
    "    print(f'Ticker: {tick} finished at {datetime.now().strftime(\"%H:%M:%S\")}. Obs = {len(pre_post)}. {i} of {len(energy_tickers)}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-05-14T00:26:45.371437Z",
     "iopub.status.busy": "2021-05-14T00:26:45.371203Z",
     "iopub.status.idle": "2021-05-14T00:26:45.381163Z",
     "shell.execute_reply": "2021-05-14T00:26:45.380524Z",
     "shell.execute_reply.started": "2021-05-14T00:26:45.371410Z"
    }
   },
   "outputs": [],
   "source": [
    "df.to_pickle(\"./energy_tickers.pkl\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## <font color='yellow'> Sentiment Measure Construction  </font>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from textblob import TextBlob\n",
    "import numpy as np\n",
    "import requests\n",
    "import pandas as pd\n",
    "import os\n",
    "import re\n",
    "import nltk\n",
    "from nltk.tokenize import RegexpTokenizer\n",
    "from nltk.corpus import stopwords\n",
    "nltk.download('stopwords')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "my_stopwords = nltk.corpus.stopwords.words('english')\n",
    "word_rooter = nltk.stem.snowball.PorterStemmer(ignore_stopwords=False).stem\n",
    "my_punctuation = '!\"$%&\\'()*+,-./:;<=>?[\\\\]^_`{|}~•@'\n",
    "\n",
    "# cleaning master function\n",
    "def clean_call(call, bigrams=False):\n",
    "    call = call.lower() # lower case\n",
    "    call = re.sub('['+my_punctuation + ']+', ' ', call) # strip punctuation\n",
    "    call = re.sub('\\s+', ' ', call) #remove double spacing\n",
    "    call = re.sub('([0-9]+)', '', call) # remove numbers\n",
    "    #call_token_list = [word for word in call.split(' ')\n",
    "    #                        if word not in my_stopwords] # remove stopwords\n",
    "    #call_token_list = [word_rooter(word) if '#' not in word else word\n",
    "    #                    for word in call_token_list] # apply word rooter\n",
    "    \n",
    "    call_token_list = [word_rooter(word) if '#' not in word else word\n",
    "                        for word in call.split(' ')] # modify word rooter to skip stop word removal\n",
    "    \n",
    "    if bigrams:\n",
    "        call_token_list = call_token_list+[call_token_list[i]+'_'+call_token_list[i+1]\n",
    "                                            for i in range(len(call_token_list)-1)]\n",
    "    call = ' '.join(call_token_list)\n",
    "    return call"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sentiment_polarity = []\n",
    "sentiment_subjectivity = []\n",
    "ID = []\n",
    "\n",
    "for sector in ['energy', 'health', 'tech']:\n",
    "    i=0\n",
    "    # Quarterly call transcripts are saved in \"directory\"\n",
    "    directory = r'/Users/pgoff/Google Drive/1_Learning_Python/Goff_Repo/Classification/' + sector + '_transcripts'\n",
    "    transcripts = [trans for trans in os.listdir(directory) if (trans.find(\".txt\") + 1)]\n",
    "\n",
    "    for file in transcripts:\n",
    "        path = './' + sector + '_transcripts/' + file \n",
    "        with open(path, 'r') as file:\n",
    "            BagOfWords = file.read().replace('\\n', '')\n",
    "            BagOfWords = clean_call(BagOfWords)\n",
    "            sentiment_call = TextBlob(BagOfWords)\n",
    "            sentiment_polarity.append(sentiment_call.sentiment[0])\n",
    "            sentiment_subjectivity.append(sentiment_call.sentiment[1])     \n",
    "            ID.append(file[:-4])\n",
    "        i+=1\n",
    "        if i%100 == 0:\n",
    "            print(f'Sector is {sector}. File {i} of {len(transcripts)}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.DataFrame(list(zip(sentiment_polarity, sentiment_subjectivity, ID)),\n",
    "               columns =['sentiment_polarity', 'sentiment_subjectivity', 'id'])\n",
    "df.to_pickle(\"./sentiment.pkl\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## <font color='yellow'> Exploratory data analysis and metric selection  </font>\n",
    "The goal is to build a model that maximizes the identification of profit-making opportunities (maximizing recall) while minimizing risk of poor investments (maximizing precision). As such, optimizing model parameters and feature selection around F1 is fitting. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-05-11T20:01:06.637407Z",
     "iopub.status.busy": "2021-05-11T20:01:06.637112Z",
     "iopub.status.idle": "2021-05-11T20:01:06.753231Z",
     "shell.execute_reply": "2021-05-11T20:01:06.752581Z",
     "shell.execute_reply.started": "2021-05-11T20:01:06.637380Z"
    }
   },
   "outputs": [],
   "source": [
    "# plotting packages\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import pickle\n",
    "\n",
    "df = pd.read_pickle(\"./tech_tickers.pkl\")\n",
    "df.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-05-11T11:20:33.285900Z",
     "iopub.status.busy": "2021-05-11T11:20:33.285696Z",
     "iopub.status.idle": "2021-05-11T11:20:33.289924Z",
     "shell.execute_reply": "2021-05-11T11:20:33.288749Z",
     "shell.execute_reply.started": "2021-05-11T11:20:33.285880Z"
    }
   },
   "outputs": [],
   "source": [
    "df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-05-11T10:26:01.325963Z",
     "iopub.status.busy": "2021-05-11T10:26:01.325758Z",
     "iopub.status.idle": "2021-05-11T10:26:01.331290Z",
     "shell.execute_reply": "2021-05-11T10:26:01.330283Z",
     "shell.execute_reply.started": "2021-05-11T10:26:01.325942Z"
    }
   },
   "outputs": [],
   "source": [
    "print(\"Number of unique companies: \", df.tick.nunique())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-05-11T20:01:12.994746Z",
     "iopub.status.busy": "2021-05-11T20:01:12.994527Z",
     "iopub.status.idle": "2021-05-11T20:01:13.031672Z",
     "shell.execute_reply": "2021-05-11T20:01:13.029726Z",
     "shell.execute_reply.started": "2021-05-11T20:01:12.994723Z"
    }
   },
   "outputs": [],
   "source": [
    "df['open_ratio'] = df.Open_post/df.Open_pre"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-05-11T20:01:15.528241Z",
     "iopub.status.busy": "2021-05-11T20:01:15.528008Z",
     "iopub.status.idle": "2021-05-11T20:01:15.533320Z",
     "shell.execute_reply": "2021-05-11T20:01:15.532470Z",
     "shell.execute_reply.started": "2021-05-11T20:01:15.528216Z"
    }
   },
   "outputs": [],
   "source": [
    "df = df.drop(['Open_post', 'High_post', 'Low_post', 'Close_post', 'Volume_post', 'Dividends_post', 'Stock Splits_post', \n",
    "              'Adj Close_post', 'Adj Close_pre', 'Dividends', 'Stock Splits', 'Adj Close'], axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-05-11T20:01:46.703339Z",
     "iopub.status.busy": "2021-05-11T20:01:46.703104Z",
     "iopub.status.idle": "2021-05-11T20:01:46.951169Z",
     "shell.execute_reply": "2021-05-11T20:01:46.950216Z",
     "shell.execute_reply.started": "2021-05-11T20:01:46.703313Z"
    }
   },
   "outputs": [],
   "source": [
    "# generate binary indicator at the 75th percentile of increases. This establishes a class-imbalance that will need to be fixed later. \n",
    "df['open_up5'] = 0\n",
    "df.loc[df['open_ratio'] >= 1.05, 'open_up5'] = 1\n",
    "\n",
    "# What is the imbalance? Histogram of ratios with line\n",
    "print(df.open_up5.value_counts(normalize=True))\n",
    "\n",
    "sns.kdeplot(data=df, x='open_ratio');\n",
    "plt.axvline(1.05, color='black');\n",
    "plt.xlabel(\"Open Ratio\")\n",
    "plt.savefig('feature_density.png');"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-05-11T10:26:13.617128Z",
     "iopub.status.busy": "2021-05-11T10:26:13.616905Z",
     "iopub.status.idle": "2021-05-11T10:26:13.919535Z",
     "shell.execute_reply": "2021-05-11T10:26:13.918688Z",
     "shell.execute_reply.started": "2021-05-11T10:26:13.617104Z"
    }
   },
   "outputs": [],
   "source": [
    "# Check scatterplot to identify any correlation between proportional increases and other metrics.\n",
    "sns.scatterplot(data=df, x='Open_pre', y='open_ratio', hue='open_up5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-05-11T10:26:17.176872Z",
     "iopub.status.busy": "2021-05-11T10:26:17.176647Z",
     "iopub.status.idle": "2021-05-11T10:26:17.780845Z",
     "shell.execute_reply": "2021-05-11T10:26:17.780060Z",
     "shell.execute_reply.started": "2021-05-11T10:26:17.176848Z"
    }
   },
   "outputs": [],
   "source": [
    "splot = sns.scatterplot(data=df, x='Volume_pre', y='open_ratio', hue='open_up5')\n",
    "splot.set(xscale=\"log\");"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-05-11T20:34:22.432650Z",
     "iopub.status.busy": "2021-05-11T20:34:22.432280Z",
     "iopub.status.idle": "2021-05-11T20:34:22.473105Z",
     "shell.execute_reply": "2021-05-11T20:34:22.471955Z",
     "shell.execute_reply.started": "2021-05-11T20:34:22.432608Z"
    }
   },
   "outputs": [],
   "source": [
    "#df['date']=pd.to_datetime(date, infer_datetime_format=True)\n",
    "df['date2'] = df['date'].apply(pd.Timestamp)\n",
    "df['dow'] = df.date2.dt.day_name()\n",
    "df['year'] = df.date2.dt.year\n",
    "df.year.value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-05-11T20:34:26.664406Z",
     "iopub.status.busy": "2021-05-11T20:34:26.664090Z",
     "iopub.status.idle": "2021-05-11T20:34:26.964056Z",
     "shell.execute_reply": "2021-05-11T20:34:26.963377Z",
     "shell.execute_reply.started": "2021-05-11T20:34:26.664375Z"
    }
   },
   "outputs": [],
   "source": [
    "sns.kdeplot(data=df, x='open_ratio', hue='dow');"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-05-11T20:36:22.234284Z",
     "iopub.status.busy": "2021-05-11T20:36:22.234080Z",
     "iopub.status.idle": "2021-05-11T20:36:22.245894Z",
     "shell.execute_reply": "2021-05-11T20:36:22.245085Z",
     "shell.execute_reply.started": "2021-05-11T20:36:22.234263Z"
    }
   },
   "outputs": [],
   "source": [
    "df = pd.get_dummies(df, columns=['dow'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-05-11T20:53:39.903554Z",
     "iopub.status.busy": "2021-05-11T20:53:39.903311Z",
     "iopub.status.idle": "2021-05-11T20:53:39.929005Z",
     "shell.execute_reply": "2021-05-11T20:53:39.928083Z",
     "shell.execute_reply.started": "2021-05-11T20:53:39.903526Z"
    }
   },
   "outputs": [],
   "source": [
    "print(f\"95th percentile of observations per stock: {df.groupby('tick').open_ratio.agg('count').quantile(q=0.95)}\")\n",
    "print(f\"75th percentile of observations per stock: {df.groupby('tick').open_ratio.agg('count').quantile(q=0.75)}\")\n",
    "print(f\"25th percentile of observations per stock:  {df.groupby('tick').open_ratio.agg('count').quantile(q=0.25)}\")\n",
    "print(f\" 5th percentile of observations per stock:  {df.groupby('tick').open_ratio.agg('count').quantile(q=0.05)}\")\n",
    "print(f\"Minimum:  {df.groupby('tick').open_ratio.agg('count').min()}\")\n",
    "print(f\"Maximum:  {df.groupby('tick').open_ratio.agg('count').max()}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-05-11T21:03:34.531145Z",
     "iopub.status.busy": "2021-05-11T21:03:34.530853Z",
     "iopub.status.idle": "2021-05-11T21:03:34.537475Z",
     "shell.execute_reply": "2021-05-11T21:03:34.536572Z",
     "shell.execute_reply.started": "2021-05-11T21:03:34.531113Z"
    }
   },
   "outputs": [],
   "source": [
    "df.groupby('year').year.count()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-05-11T21:26:55.797401Z",
     "iopub.status.busy": "2021-05-11T21:26:55.797103Z",
     "iopub.status.idle": "2021-05-11T21:26:55.817495Z",
     "shell.execute_reply": "2021-05-11T21:26:55.816250Z",
     "shell.execute_reply.started": "2021-05-11T21:26:55.797348Z"
    }
   },
   "outputs": [],
   "source": [
    "df[:2]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## <font color='yellow'> Baselining </font>\n",
    "Initial model with volume, dividend, year, and day of week."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-05-11T22:28:12.640042Z",
     "iopub.status.busy": "2021-05-11T22:28:12.639805Z",
     "iopub.status.idle": "2021-05-11T22:28:12.649929Z",
     "shell.execute_reply": "2021-05-11T22:28:12.647688Z",
     "shell.execute_reply.started": "2021-05-11T22:28:12.640017Z"
    }
   },
   "outputs": [],
   "source": [
    "# visualization imports\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "plt.style.use('fivethirtyeight')\n",
    "\n",
    "%matplotlib inline\n",
    "\n",
    "# modeling imports\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.preprocessing import PolynomialFeatures\n",
    "from sklearn.model_selection import cross_val_score\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.model_selection import KFold\n",
    "\n",
    "# metrics imports\n",
    "from sklearn.metrics import f1_score, precision_score, recall_score, accuracy_score, roc_auc_score\n",
    "from sklearn.metrics import confusion_matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-05-11T22:39:02.075582Z",
     "iopub.status.busy": "2021-05-11T22:39:02.075072Z",
     "iopub.status.idle": "2021-05-11T22:39:02.086748Z",
     "shell.execute_reply": "2021-05-11T22:39:02.085821Z",
     "shell.execute_reply.started": "2021-05-11T22:39:02.075496Z"
    }
   },
   "outputs": [],
   "source": [
    "X_train = df[['Volume_pre', 'Dividends_pre', 'year', 'dow_Monday', 'dow_Tuesday', \n",
    "              'dow_Wednesday', 'dow_Thursday', 'dow_Friday', 'dow_Saturday']][df.year<2021]\n",
    "y_train = df['open_up5'][df.year<2021]\n",
    "\n",
    "X_test = df[['Volume_pre', 'Dividends_pre', 'year', 'dow_Monday', 'dow_Tuesday', \n",
    "              'dow_Wednesday', 'dow_Thursday', 'dow_Friday', 'dow_Saturday']][df.year==2021]\n",
    "y_test = df['open_up5'][df.year==2021]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-05-11T22:39:04.117186Z",
     "iopub.status.busy": "2021-05-11T22:39:04.116949Z",
     "iopub.status.idle": "2021-05-11T22:39:04.136597Z",
     "shell.execute_reply": "2021-05-11T22:39:04.135966Z",
     "shell.execute_reply.started": "2021-05-11T22:39:04.117160Z"
    }
   },
   "outputs": [],
   "source": [
    "# Create polynomial features\n",
    "poly = PolynomialFeatures(degree=2)\n",
    "X_train_poly = poly.fit_transform(X_train)\n",
    "\n",
    "# Don't forget to standard scale your data for regularized regression\n",
    "scaler = StandardScaler()\n",
    "X_train_poly_scaled = scaler.fit_transform(X_train_poly)\n",
    "\n",
    "# Create the same polynomial features and apply the same scaler to test set\n",
    "X_test_poly = poly.fit_transform(X_test)\n",
    "X_test_poly_scaled = scaler.transform(X_test_poly)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-05-11T21:54:15.136666Z",
     "iopub.status.busy": "2021-05-11T21:54:15.136348Z",
     "iopub.status.idle": "2021-05-11T21:54:15.141557Z",
     "shell.execute_reply": "2021-05-11T21:54:15.140317Z",
     "shell.execute_reply.started": "2021-05-11T21:54:15.136619Z"
    }
   },
   "outputs": [],
   "source": [
    "unique, counts = np.unique(y_predict, return_counts=True)\n",
    "\n",
    "print(np.asarray((unique, counts)).T)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-05-11T22:39:07.882294Z",
     "iopub.status.busy": "2021-05-11T22:39:07.882044Z",
     "iopub.status.idle": "2021-05-11T22:39:07.888749Z",
     "shell.execute_reply": "2021-05-11T22:39:07.887422Z",
     "shell.execute_reply.started": "2021-05-11T22:39:07.882268Z"
    }
   },
   "outputs": [],
   "source": [
    "#Initial\n",
    "y_train.value_counts(dropna=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-05-11T22:39:34.879580Z",
     "iopub.status.busy": "2021-05-11T22:39:34.879340Z",
     "iopub.status.idle": "2021-05-11T22:39:34.884091Z",
     "shell.execute_reply": "2021-05-11T22:39:34.883146Z",
     "shell.execute_reply.started": "2021-05-11T22:39:34.879557Z"
    }
   },
   "outputs": [],
   "source": [
    "len(y) # Initial"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-05-11T22:40:00.931920Z",
     "iopub.status.busy": "2021-05-11T22:40:00.931659Z",
     "iopub.status.idle": "2021-05-11T22:40:00.937043Z",
     "shell.execute_reply": "2021-05-11T22:40:00.936099Z",
     "shell.execute_reply.started": "2021-05-11T22:40:00.931891Z"
    }
   },
   "outputs": [],
   "source": [
    "len(y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-05-11T22:39:49.132121Z",
     "iopub.status.busy": "2021-05-11T22:39:49.131882Z",
     "iopub.status.idle": "2021-05-11T22:39:49.136407Z",
     "shell.execute_reply": "2021-05-11T22:39:49.135238Z",
     "shell.execute_reply.started": "2021-05-11T22:39:49.132093Z"
    }
   },
   "outputs": [],
   "source": [
    "X, y = np.array(X_train_poly_scaled), np.array(y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-05-11T22:48:02.686433Z",
     "iopub.status.busy": "2021-05-11T22:48:02.686199Z",
     "iopub.status.idle": "2021-05-11T22:48:02.999357Z",
     "shell.execute_reply": "2021-05-11T22:48:02.998534Z",
     "shell.execute_reply.started": "2021-05-11T22:48:02.686406Z"
    }
   },
   "outputs": [],
   "source": [
    "kf = KFold(n_splits=5, shuffle=True, random_state = 1618)\n",
    "cv_precision, cv_recall, cv_f1, cv_AUC = [], [], [], [] #collect the validation results \n",
    "\n",
    "for train_ind, val_ind in kf.split(X, y):\n",
    "    \n",
    "    X_train, y_train = X[train_ind], y[train_ind]\n",
    "    X_val, y_val = X[val_ind], y[val_ind] \n",
    "    \n",
    "    #simple linear regression\n",
    "    m1_log = LogisticRegression(solver='liblinear')\n",
    "\n",
    "    m1_log.fit(X_train, y_train)\n",
    "    y_predict = m1_log.predict(X_val) \n",
    "    \n",
    "    cv_precision.append(precision_score(y_val, y_predict))\n",
    "    cv_recall.append(recall_score(y_val, y_predict))\n",
    "    cv_f1.append(f1_score(y_val, y_predict))\n",
    "    cv_AUC.append(roc_auc_score(y_val, m1_log.predict_proba(X_val)[:, 1]))\n",
    "\n",
    "print(f'Baseline Precision score: {np.mean(cv_precision):.3f}')\n",
    "print(f'Baseline Recall score:    {np.mean(cv_recall):.3f}')\n",
    "print(f'Baseline F1 score:        {np.mean(cv_f1):.3f}')\n",
    "print(f'Baseline ROC AUC score:   {np.mean(cv_AUC):.3f}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-05-11T22:11:22.865521Z",
     "iopub.status.busy": "2021-05-11T22:11:22.865147Z",
     "iopub.status.idle": "2021-05-11T22:11:22.896117Z",
     "shell.execute_reply": "2021-05-11T22:11:22.893635Z",
     "shell.execute_reply.started": "2021-05-11T22:11:22.865461Z"
    }
   },
   "outputs": [],
   "source": [
    "# Imbalance adjustment\n",
    "\n",
    "# Other models (knn, RF, ExtraTree, boost)\n",
    "knn = KNeighborsClassifier(n_neighbors=5)\n",
    "\n",
    "## Grid search for hyper parameter tuning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-05-08T16:20:51.110630Z",
     "iopub.status.busy": "2021-05-08T16:20:51.110353Z",
     "iopub.status.idle": "2021-05-08T16:20:52.858065Z",
     "shell.execute_reply": "2021-05-08T16:20:52.856865Z",
     "shell.execute_reply.started": "2021-05-08T16:20:51.110601Z"
    }
   },
   "outputs": [],
   "source": [
    "#https://ourcodingclub.github.io/tutorials/topic-modelling-python/\n",
    "\n",
    "# model building package\n",
    "import sklearn\n",
    "\n",
    "# package to clean text\n",
    "import re"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-05-08T17:26:33.548438Z",
     "iopub.status.busy": "2021-05-08T17:26:33.548099Z",
     "iopub.status.idle": "2021-05-08T17:26:33.554583Z",
     "shell.execute_reply": "2021-05-08T17:26:33.553072Z",
     "shell.execute_reply.started": "2021-05-08T17:26:33.548394Z"
    }
   },
   "outputs": [],
   "source": [
    "each_file = './transcripts/' + subset_transcripts[0]\n",
    "with open(each_file, 'r') as file:\n",
    "    data = file.read().replace('\\n', '')\n",
    "\n",
    "data = [data]\n",
    "tdf = pd.DataFrame(data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-05-08T17:26:35.304044Z",
     "iopub.status.busy": "2021-05-08T17:26:35.303758Z",
     "iopub.status.idle": "2021-05-08T17:26:35.348631Z",
     "shell.execute_reply": "2021-05-08T17:26:35.347806Z",
     "shell.execute_reply.started": "2021-05-08T17:26:35.304012Z"
    }
   },
   "outputs": [],
   "source": [
    "for x in subset_transcripts[1:]:\n",
    "    each_file = './transcripts/' + x\n",
    "    with open(each_file, 'r') as file:\n",
    "        data = file.read().replace('\\n', '')\n",
    "    \n",
    "    df_length = len(tdf)\n",
    "    tdf.loc[df_length] = data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-05-08T17:26:37.735713Z",
     "iopub.status.busy": "2021-05-08T17:26:37.735487Z",
     "iopub.status.idle": "2021-05-08T17:26:37.739872Z",
     "shell.execute_reply": "2021-05-08T17:26:37.738802Z",
     "shell.execute_reply.started": "2021-05-08T17:26:37.735689Z"
    }
   },
   "outputs": [],
   "source": [
    "tdf.rename(columns = {0: 'call',}, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-05-08T16:33:04.469458Z",
     "iopub.status.busy": "2021-05-08T16:33:04.468965Z",
     "iopub.status.idle": "2021-05-08T16:33:05.859377Z",
     "shell.execute_reply": "2021-05-08T16:33:05.857767Z",
     "shell.execute_reply.started": "2021-05-08T16:33:04.469417Z"
    }
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-05-08T17:27:26.623536Z",
     "iopub.status.busy": "2021-05-08T17:27:26.623229Z",
     "iopub.status.idle": "2021-05-08T17:27:26.634029Z",
     "shell.execute_reply": "2021-05-08T17:27:26.633280Z",
     "shell.execute_reply.started": "2021-05-08T17:27:26.623493Z"
    }
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-05-08T17:27:29.035850Z",
     "iopub.status.busy": "2021-05-08T17:27:29.035629Z",
     "iopub.status.idle": "2021-05-08T17:27:30.314257Z",
     "shell.execute_reply": "2021-05-08T17:27:30.313498Z",
     "shell.execute_reply.started": "2021-05-08T17:27:29.035827Z"
    }
   },
   "outputs": [],
   "source": [
    "tdf['clean_call']=tdf.call.apply(clean_call)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-05-08T17:12:59.638366Z",
     "iopub.status.busy": "2021-05-08T17:12:59.637703Z",
     "iopub.status.idle": "2021-05-08T17:12:59.642682Z",
     "shell.execute_reply": "2021-05-08T17:12:59.641401Z",
     "shell.execute_reply.started": "2021-05-08T17:12:59.638261Z"
    }
   },
   "outputs": [],
   "source": [
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-05-08T17:09:34.792150Z",
     "iopub.status.busy": "2021-05-08T17:09:34.791906Z",
     "iopub.status.idle": "2021-05-08T17:09:35.048452Z",
     "shell.execute_reply": "2021-05-08T17:09:35.047780Z",
     "shell.execute_reply.started": "2021-05-08T17:09:34.792123Z"
    }
   },
   "outputs": [],
   "source": [
    "each_file = './transcripts/' + subset_transcripts[0]\n",
    "with open(each_file, 'r') as file:\n",
    "    bagOfWordsA = file.read().replace('\\n', '')\n",
    "bagOfWordsA = clean_call(bagOfWordsA)\n",
    "bagOfWordsA = bagOfWordsA.split(' ')\n",
    "\n",
    "each_file = './transcripts/' + subset_transcripts[1]\n",
    "with open(each_file, 'r') as file:\n",
    "    bagOfWordsB = file.read().replace('\\n', '')\n",
    "bagOfWordsB = clean_call(bagOfWordsB)\n",
    "bagOfWordsB = bagOfWordsB.split(' ')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-05-08T17:09:38.784212Z",
     "iopub.status.busy": "2021-05-08T17:09:38.783982Z",
     "iopub.status.idle": "2021-05-08T17:09:38.790011Z",
     "shell.execute_reply": "2021-05-08T17:09:38.788250Z",
     "shell.execute_reply.started": "2021-05-08T17:09:38.784188Z"
    }
   },
   "outputs": [],
   "source": [
    "uniqueWords = set(bagOfWordsA).union(set(bagOfWordsB))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-05-08T17:09:43.451790Z",
     "iopub.status.busy": "2021-05-08T17:09:43.451559Z",
     "iopub.status.idle": "2021-05-08T17:09:43.459582Z",
     "shell.execute_reply": "2021-05-08T17:09:43.458868Z",
     "shell.execute_reply.started": "2021-05-08T17:09:43.451766Z"
    }
   },
   "outputs": [],
   "source": [
    "numOfWordsA = dict.fromkeys(uniqueWords, 0)\n",
    "for word in bagOfWordsA:\n",
    "    numOfWordsA[word] += 1\n",
    "\n",
    "numOfWordsB = dict.fromkeys(uniqueWords, 0)\n",
    "for word in bagOfWordsB:\n",
    "    numOfWordsB[word] += 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-05-08T17:09:49.764186Z",
     "iopub.status.busy": "2021-05-08T17:09:49.763634Z",
     "iopub.status.idle": "2021-05-08T17:09:49.770816Z",
     "shell.execute_reply": "2021-05-08T17:09:49.769259Z",
     "shell.execute_reply.started": "2021-05-08T17:09:49.764134Z"
    }
   },
   "outputs": [],
   "source": [
    "# Term Frequency:\n",
    "def computeTF(wordDict, bagOfWords):\n",
    "    tfDict = {}\n",
    "    bagOfWordsCount = len(bagOfWords)\n",
    "    for word, count in wordDict.items():\n",
    "        tfDict[word] = count / float(bagOfWordsCount)\n",
    "    return tfDict\n",
    "\n",
    "# TF is calculated for each document\n",
    "tfA = computeTF(numOfWordsA, bagOfWordsA)\n",
    "tfB = computeTF(numOfWordsB, bagOfWordsB)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-05-08T17:09:52.084920Z",
     "iopub.status.busy": "2021-05-08T17:09:52.084700Z",
     "iopub.status.idle": "2021-05-08T17:09:52.094886Z",
     "shell.execute_reply": "2021-05-08T17:09:52.093577Z",
     "shell.execute_reply.started": "2021-05-08T17:09:52.084897Z"
    }
   },
   "outputs": [],
   "source": [
    "def computeIDF(documents):\n",
    "    import math\n",
    "    N = len(documents)\n",
    "    \n",
    "    idfDict = dict.fromkeys(documents[0].keys(), 0)\n",
    "    for document in documents:\n",
    "        for word, val in document.items():\n",
    "            if val > 0:\n",
    "                idfDict[word] += 1\n",
    "    \n",
    "    for word, val in idfDict.items():\n",
    "        idfDict[word] = math.log(N / float(val))\n",
    "    return idfDict\n",
    "\n",
    "# IDF is calculated across all documents:\n",
    "idfs = computeIDF([numOfWordsA, numOfWordsB])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-05-08T17:09:54.208261Z",
     "iopub.status.busy": "2021-05-08T17:09:54.207955Z",
     "iopub.status.idle": "2021-05-08T17:09:54.274913Z",
     "shell.execute_reply": "2021-05-08T17:09:54.274206Z",
     "shell.execute_reply.started": "2021-05-08T17:09:54.208233Z"
    }
   },
   "outputs": [],
   "source": [
    "# TF-IDF:\n",
    "def computeTFIDF(tfBagOfWords, idfs):\n",
    "    tfidf = {}\n",
    "    for word, val in tfBagOfWords.items():\n",
    "        tfidf[word] = val * idfs[word]\n",
    "    return tfidf\n",
    "\n",
    "tfidfA = computeTFIDF(tfA, idfs)\n",
    "tfidfB = computeTFIDF(tfB, idfs)\n",
    "df = pd.DataFrame([tfidfA, tfidfB])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-05-08T17:13:08.451033Z",
     "iopub.status.busy": "2021-05-08T17:13:08.450810Z",
     "iopub.status.idle": "2021-05-08T17:13:08.800919Z",
     "shell.execute_reply": "2021-05-08T17:13:08.800263Z",
     "shell.execute_reply.started": "2021-05-08T17:13:08.451010Z"
    }
   },
   "outputs": [],
   "source": [
    "each_file = './transcripts/' + subset_transcripts[0]\n",
    "with open(each_file, 'r') as file:\n",
    "    bagOfWordsA = file.read().replace('\\n', '')\n",
    "bagOfWordsA = clean_call(bagOfWordsA)\n",
    "\n",
    "each_file = './transcripts/' + subset_transcripts[1]\n",
    "with open(each_file, 'r') as file:\n",
    "    bagOfWordsB = file.read().replace('\\n', '')\n",
    "bagOfWordsB = clean_call(bagOfWordsB)\n",
    "\n",
    "# TF-IDF Directly from sklearn:\n",
    "vectorizer = TfidfVectorizer()\n",
    "vectors = vectorizer.fit_transform([bagOfWordsA, bagOfWordsB])\n",
    "feature_names = vectorizer.get_feature_names()\n",
    "dense = vectors.todense()\n",
    "denselist = dense.tolist()\n",
    "df = pd.DataFrame(denselist, columns=feature_names)\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-05-08T17:29:28.661260Z",
     "iopub.status.busy": "2021-05-08T17:29:28.661050Z",
     "iopub.status.idle": "2021-05-08T17:29:28.679707Z",
     "shell.execute_reply": "2021-05-08T17:29:28.678376Z",
     "shell.execute_reply.started": "2021-05-08T17:29:28.661237Z"
    }
   },
   "outputs": [],
   "source": [
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-05-08T17:29:43.023217Z",
     "iopub.status.busy": "2021-05-08T17:29:43.022835Z",
     "iopub.status.idle": "2021-05-08T17:29:43.216833Z",
     "shell.execute_reply": "2021-05-08T17:29:43.215616Z",
     "shell.execute_reply.started": "2021-05-08T17:29:43.023177Z"
    }
   },
   "outputs": [],
   "source": [
    "# TF-IDF Directly from sklearn:\n",
    "vectorizer = TfidfVectorizer()\n",
    "vectors = vectorizer.fit_transform(tdf.clean_call)\n",
    "feature_names = vectorizer.get_feature_names()\n",
    "dense = vectors.todense()\n",
    "denselist = dense.tolist()\n",
    "dtm = pd.DataFrame(denselist, columns=feature_names)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-05-08T17:45:11.353085Z",
     "iopub.status.busy": "2021-05-08T17:45:11.352861Z",
     "iopub.status.idle": "2021-05-08T17:45:11.361790Z",
     "shell.execute_reply": "2021-05-08T17:45:11.360212Z",
     "shell.execute_reply.started": "2021-05-08T17:45:11.353063Z"
    }
   },
   "outputs": [],
   "source": [
    "feature_names2 = [re.sub('([0-9]+)', '', name) for name in feature_names]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-05-08T17:45:50.555579Z",
     "iopub.status.busy": "2021-05-08T17:45:50.555348Z",
     "iopub.status.idle": "2021-05-08T17:45:50.647018Z",
     "shell.execute_reply": "2021-05-08T17:45:50.645293Z",
     "shell.execute_reply.started": "2021-05-08T17:45:50.555555Z"
    }
   },
   "outputs": [],
   "source": [
    "# 3rd party imports\n",
    "import numpy as np\n",
    "from sklearn import datasets\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from advanced_pca import CustomPCA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-05-08T17:54:38.720471Z",
     "iopub.status.busy": "2021-05-08T17:54:38.720239Z",
     "iopub.status.idle": "2021-05-08T17:54:38.742001Z",
     "shell.execute_reply": "2021-05-08T17:54:38.740471Z",
     "shell.execute_reply.started": "2021-05-08T17:54:38.720447Z"
    }
   },
   "outputs": [],
   "source": [
    "dtm_r = _df2mtr(dtm)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-05-08T17:45:50.555579Z",
     "iopub.status.busy": "2021-05-08T17:45:50.555348Z",
     "iopub.status.idle": "2021-05-08T17:45:50.647018Z",
     "shell.execute_reply": "2021-05-08T17:45:50.645293Z",
     "shell.execute_reply.started": "2021-05-08T17:45:50.555555Z"
    }
   },
   "outputs": [],
   "source": [
    "# load dataset\n",
    "X_std = StandardScaler().fit_transform(dtm)\n",
    "\n",
    "# fit pca objects with and without rotation with 5 principal components\n",
    "standard_pca3 = CustomPCA(n_components=5).fit(X_std)\n",
    "varimax_pca3 = CustomPCA(n_components=5, rotation='varimax').fit(X_std)\n",
    "\n",
    "# display factor matrices and number of cross loadings\n",
    "#print('Factor matrix:\\n', standard_pca3.components_.round(1))\n",
    "print(' Number of cross-loadings:', standard_pca3.count_cross_loadings())\n",
    "#print('\\nRotated factor matrix:\\n', varimax_pca3.components_.round(1))\n",
    "print(' Number of cross_loadings:', varimax_pca3.count_cross_loadings())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "467 within technology sector <br>\n",
    "527 within healthcare sector - use these as for train/validate <br>\n",
    "258 within energy sector - use this as a sector holdout for testing. <br>\n",
    "\n",
    "12 quarterly reports spans 4 years. <br>\n",
    "2021 Q1 <br>\n",
    "2020 Q1 Q2 Q3 Q4 <br>\n",
    "2019 Q1 Q2 Q3 Q4 <br>\n",
    "2018    Q2 Q3 Q4 <br>\n",
    "\n",
    "I'll use 2021 Q1 and 2019 Q3 as my secondary test data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-05-06T20:41:43.426494Z",
     "iopub.status.busy": "2021-05-06T20:41:43.426284Z",
     "iopub.status.idle": "2021-05-06T20:41:43.450641Z",
     "shell.execute_reply": "2021-05-06T20:41:43.449073Z",
     "shell.execute_reply.started": "2021-05-06T20:41:43.426472Z"
    }
   },
   "outputs": [],
   "source": [
    "tech_tickers = [\"AAPL\" ,\"MSFT\" ,\"TSM\" ,\"NVDA\" ,\"ASML\" ,\"ORCL\" ,\"INTC\" ,\"ADBE\" ,\"CSCO\" ,\"CRM\" ,\"ACN\" ,\"AVGO\" ,\"TXN\" ,\"SAP\" ,\"QCOM\" ,\"SHOP\" ,\"IBM\" ,\"SONY\" ,\"AMAT\" ,\n",
    "                \"INTU\" ,\"SQ\" ,\"NOW\" ,\"MU\" ,\"AMD\" ,\"FIS\" ,\"LRCX\" ,\"UBER\" ,\"FISV\" ,\"INFY\" ,\"DELL\" ,\"VMW\" ,\"ADSK\" ,\"ADI\" ,\"SNOW\" ,\"WDAY\" ,\"TEAM\" ,\"NXPI\" ,\"KLAC\" ,\n",
    "                \"ERIC\" ,\"HPQ\" ,\"TEL\" ,\"CRWD\" ,\"CTSH\" ,\"MCHP\" ,\"PLTR\" ,\"WIT\" ,\"DOCU\" ,\"SNPS\" ,\"CDNS\" ,\"GLW\" ,\"FTNT\" ,\"STM\" ,\"PANW\" ,\"MSI\" ,\"MRVL\" ,\"OKTA\" ,\"XLNX\" ,\n",
    "                \"SWKS\" ,\"ANSS\" ,\"NOK\" ,\"GRMN\" ,\"KEYS\" ,\"FTV-PA\" ,\"EPAM\" ,\"MXIM\" ,\"VRSN\" ,\"ZBRA\" ,\"ANET\" ,\"CDW\" ,\"FTV\" ,\"CAJ\" ,\"U\" ,\"WORK\" ,\"FLT\" ,\"RNG\" ,\"GIB\" ,\n",
    "                \"HUBS\" ,\"ZS\" ,\"DDOG\" ,\"NET\" ,\"WDC\" ,\"STX\" ,\"HPE\" ,\"TER\" ,\"QRVO\" ,\"IT\" ,\"UMC\" ,\"APH\" ,\"BR\" ,\"TRMB\" ,\"STNE\" ,\"SPLK\" ,\"PAYC\" ,\"LOGI\" ,\"SSNC\" ,\"XM\" ,\n",
    "                \"AKAM\" ,\"ZI\" ,\"NTAP\" ,\"COUP\" ,\"CHKP\" ,\"CLVT\" ,\"UI\" ,\"TYL\" ,\"LYFT\" ,\"ZEN\" ,\"TDY\" ,\"WIX\" ,\"ON\" ,\"PTC\" ,\"NUAN\" ,\"MPWR\" ,\"ENTG\" ,\"CTXS\" ,\"LDOS\" ,\"ASX\" ,\n",
    "                \"NICE\" ,\"FICO\" ,\"CGNX\" ,\"PAGS\" ,\"GDDY\" ,\"AFRM\" ,\"BSY\" ,\"CDAY\" ,\"DT\" ,\"OTEX\" ,\"NLOK\" ,\"JKHY\" ,\"BKI\" ,\"FFIV\" ,\"TUYA\" ,\"SEDG\" ,\"BILL\" ,\"IPGP\" ,\"AVLR\" ,\n",
    "                \"CREE\" ,\"OLED\" ,\"DBX\" ,\"DOX\" ,\"MKSI\" ,\"DLB\" ,\"PSFE\" ,\"PFPT\" ,\"MCFE\" ,\"PEGA\" ,\"DNB\" ,\"ESTC\" ,\"PCTY\" ,\"RUN\" ,\"FLEX\" ,\"ST\" ,\"KC\" ,\"JNPR\" ,\"G\" ,\"WEX\" ,\n",
    "                \"AZPN\" ,\"DXC\" ,\"ARW\" ,\"GLOB\" ,\"MANH\" ,\"TIXT\" ,\"GWRE\" ,\"CIEN\" ,\"CNXC\" ,\"JBL\" ,\"FSLR\" ,\"FLIR\" ,\"PLAN\" ,\"LPL\" ,\"LSPD\" ,\"EEFT\" ,\"BRKS\" ,\"COMP\" ,\"LSCC\" ,\n",
    "                \"FOUR\" ,\"SMAR\" ,\"CDK\" ,\"CACI\" ,\"LAZR\" ,\"LFUS\" ,\"IIVI\" ,\"SNX\" ,\"COHR\" ,\"LITE\" ,\"NCR\" ,\"BMBL\" ,\"BL\" ,\"MSTR\" ,\"SLAB\" ,\"CLGX\" ,\"NTNX\" ,\"VNT\" ,\"DAVA\" ,\n",
    "                \"OCFT\" ,\"CRCT\" ,\"AI\" ,\"NATI\" ,\"TDC\" ,\"JCOM\" ,\"SWI\" ,\"NCNO\" ,\"DSGX\" ,\"AYX\" ,\"SAIC\" ,\"ACVA\" ,\"DQ\" ,\"QTWO\" ,\"CD\" ,\"PSTG\" ,\"DCT\" ,\"POWI\" ,\"RXT\" ,\"XRX\" ,\n",
    "                \"AMKR\" ,\"FSLY\" ,\"ALTR\" ,\"DOCN\" ,\"PRSP\" ,\"ALGM\" ,\"TTEC\" ,\"SYNA\" ,\"CCMP\" ,\"BB\" ,\"ASAN\" ,\"SONO\" ,\"CYBR\" ,\"FEYE\" ,\"NOVT\" ,\"CRUS\" ,\"ACIW\" ,\"AVT\" ,\"SWCH\" ,\n",
    "                \"OLO\" ,\"ATC\" ,\"SAIL\" ,\"API\" ,\"WK\" ,\"ALRM\" ,\"SMTC\" ,\"MDLA\" ,\"SABR\" ,\"MSP\" ,\"SPWR\" ,\"FROG\" ,\"QLYS\" ,\"TENB\" ,\"ENV\" ,\"JAMF\" ,\"NEWR\" ,\"DIOD\" ,\"VICR\" ,\n",
    "                \"MTSI\" ,\"VIAV\" ,\"ROG\" ,\"STMP\" ,\"SPSC\" ,\"VSH\" ,\"CLDR\" ,\"VSAT\" ,\"COMM\" ,\"ITRI\" ,\"MANT\" ,\"LPSN\" ,\"NSIT\" ,\"CRNC\" ,\"EXLS\" ,\"VNET\" ,\"BOX\" ,\"BLKB\" ,\"VRNT\" ,\n",
    "                \"RAMP\" ,\"AMBA\" ,\"FN\" ,\"CVLT\" ,\"EGHT\" ,\"ONTO\" ,\"NOVA\" ,\"PD\" ,\"EVTC\" ,\"BAND\" ,\"CRSR\" ,\"KLIC\" ,\"FORM\" ,\"TSEM\" ,\"ESE\" ,\"YALA\" ,\"CALX\" ,\"IRBT\" ,\"MIME\" ,\n",
    "                \"CSOD\" ,\"SANM\" ,\"PLXS\" ,\"DM\" ,\"NVMI\" ,\"MXL\" ,\"SATS\" ,\"SVMK\" ,\"CSIQ\" ,\"DDD\" ,\"SIMO\" ,\"RIOT\" ,\"PRFT\" ,\"MFGP\" ,\"AVYA\" ,\"SEMR\" ,\"BTRS\" ,\"RMBS\" ,\"HIMX\" ,\n",
    "                \"XPER\" ,\"MVIS\" ,\"VLDR\" ,\"PING\" ,\"UCTT\" ,\"PRGS\" ,\"NTCT\" ,\"KN\" ,\"EB\" ,\"MAXR\" ,\"GB\" ,\"ZUO\" ,\"SMCI\" ,\"ONTF\" ,\"DSP\" ,\"PRO\" ,\"OUST\" ,\"MEI\" ,\"OSIS\" ,\"EPAY\" ,\n",
    "                \"SYKE\" ,\"SUMO\" ,\"INFN\" ,\"RAAS\" ,\"PAR\" ,\"PLT\" ,\"TTMI\" ,\"YEXT\" ,\"DCBO\" ,\"CGNT\" ,\"COHU\" ,\"SPNS\" ,\"GPRO\" ,\"CNDT\" ,\"UIS\" ,\"ICHR\" ,\"VRNS\" ,\"CSGS\" ,\"JKS\" ,\n",
    "                \"MTLS\" ,\"EXTR\" ,\"FORTY\" ,\"QADA\" ,\"PLUS\" ,\"ACLS\" ,\"MODN\" ,\"QADB\" ,\"MLAB\" ,\"CNXN\" ,\"RDWR\" ,\"LINX\" ,\"FARO\" ,\"OPRA\" ,\"AGYS\" ,\"GSKY\" ,\"DBD\" ,\"VCRA\" ,\"NTGR\" ,\n",
    "                \"CEVA\" ,\"PI\" ,\"SGH\" ,\"BHE\" ,\"SSYS\" ,\"VECO\" ,\"IMOS\" ,\"SCWX\" ,\"CLS\" ,\"CTS\" ,\"AUDC\" ,\"LASR\" ,\"IIIV\" ,\"EBIX\" ,\"MX\" ,\"ADTN\" ,\"PLAB\" ,\"UEIC\" ,\"SCSC\" ,\"INSG\" ,\n",
    "                \"MGIC\" ,\"AOSL\" ,\"HLIT\" ,\"ATEN\" ,\"CASA\" ,\"PDFS\" ,\"ABST\" ,\"ECOM\" ,\"ZEPP\" ,\"AMSWA\" ,\"ALLT\" ,\"CMTL\" ,\"BCOV\" ,\"ITRN\" ,\"MAXN\" ,\"GILT\" ,\"SWIR\" ,\"DGII\" ,\n",
    "                \"VIOT\" ,\"DMRC\" ,\"HCKT\" ,\"SOL\" ,\"EBON\" ,\"NPTN\" ,\"ETWO\" ,\"CAMP\" ,\"VPG\" ,\"VOXX\" ,\"ZIXI\" ,\"AXTI\" ,\"LLNW\" ,\"DSPG\" ,\"VIAO\" ,\"VHC\" ,\"TUFN\" ,\"HBB\" ,\"SILC\" ,\n",
    "                \"UEPS\" ,\"DAKT\" ,\"CMCM\" ,\"MIXT\" ,\"WTRH\" ,\"CRNT\" ,\"SOS\" ,\"KVHI\" ,\"IMMR\" ,\"BELFA\" ,\"BELFB\" ,\"EXFO\" ,\"LYTS\" ,\"CIH\" ,\"OIIM\" ,\"SQNS\" ,\"AVNW\" ,\"CTG\" ,\"GSIT\" ,\n",
    "                \"ASYS\" ,\"SREV\" ,\"SNCR\" ,\"SPI\" ,\"CTK\" ,\"PCTI\" ,\"RELL\" ,\"RCAT\" ,\"TESS\" ,\"UTSI\" ,\"MINDP\" ,\"SEAC\" ,\"MIND\" ,\"KNBE\" ,\"SABRP\" ,\"IIVIP\" ,\"APP\" ,\"VZIO\" ,\"CTLP\" ,\n",
    "                \"STEM\" ,\"COIN\" ,\"AVGOP\" ,\"ALKT\" ,\"PATH\" ,\"DV\"]\n",
    "len(tech_tickers)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-05-06T20:41:45.415560Z",
     "iopub.status.busy": "2021-05-06T20:41:45.415329Z",
     "iopub.status.idle": "2021-05-06T20:41:45.438928Z",
     "shell.execute_reply": "2021-05-06T20:41:45.436848Z",
     "shell.execute_reply.started": "2021-05-06T20:41:45.415536Z"
    }
   },
   "outputs": [],
   "source": [
    "health_tickers = [\"JNJ\" ,\"UNH\" ,\"PFE\" ,\"ABT\" ,\"ABBV\" ,\"NVS\" ,\"MRK\" ,\"TMO\" ,\"LLY\" ,\"DHR\" ,\"MDT\" ,\"NVO\" ,\"DHR-PA\" ,\"AMGN\" ,\"BMY\" ,\"AZN\" ,\"SNY\" ,\"CVS\" ,\"ISRG\" ,\"ANTM\" ,\"SYK\" ,\"GSK\" ,\"CI\" ,\"GILD\" ,\"ZTS\" ,\"HCA\" ,\"BDX\" ,\"MRNA\" ,\"BSX\" ,\"HUM\" ,\"EW\" ,\"VRTX\" ,\"ILMN\" ,\"REGN\" ,\"TAK\" ,\"PHG\" ,\"WBA\" ,\"ALGN\" ,\"IDXX\" ,\"BAX\" ,\"IQV\" ,\"BIIB\" ,\"A\" ,\"BNTX\" ,\"VEEV\" ,\"CNC\" ,\"ALXN\" ,\"ZBH\" ,\"DXCM\" ,\"ALC\" ,\"MTD\" ,\"MCK\" ,\"BGNE\" ,\"RMD\" ,\"LH\" ,\"RPRX\" ,\"SGEN\" ,\"GMAB\" ,\"WST\" ,\"ABC\" ,\"CERN\" ,\"FMS\" ,\"TDOC\" ,\"COO\" ,\"HZNP\" ,\"NVCR\" ,\"WAT\" ,\"TFX\" ,\"SNN\" ,\"BIO-B\" ,\"DGX\" ,\"INCY\" ,\"CTLT\" ,\"BIO\" ,\"STE\" ,\"GRFS\" ,\"VTRS\" ,\"HOLX\" ,\"CRL\" ,\"PODD\" ,\"CAH\" ,\"PPD\" ,\"TECH\" ,\"MOH\" ,\"TXG\" ,\"ALNY\" ,\"PKI\" ,\"XRAY\" ,\"ELAN\" ,\"BMRN\" ,\"GDRX\" ,\"OSH\" ,\"DVA\" ,\"GH\" ,\"ABMD\" ,\"ARGX\" ,\"UHS\" ,\"MASI\" ,\"ICLR\" ,\"RDY\" ,\"NVAX\" ,\"TEVA\" ,\"HSIC\" ,\"PRAH\" ,\"QGEN\" ,\"BRKR\" ,\"RGEN\" ,\"PEN\" ,\"BHC\" ,\"JAZZ\" ,\"MRVI\" ,\"CGC\" ,\"UTHR\" ,\"EHC\" ,\"SYNH\" ,\"NBIX\" ,\"AMED\" ,\"NTRA\" ,\"RARE\" ,\"ABCL\" ,\"CHE\" ,\"MRTX\" ,\"BBIO\" ,\"EXEL\" ,\"HRC\" ,\"GMED\" ,\"NVST\" ,\"ASND\" ,\"CHNG\" ,\"THC\" ,\"ARWR\" ,\"SHC\" ,\"DNLI\" ,\"HALO\" ,\"RCM\" ,\"LHCG\" ,\"IART\" ,\"IBRX\" ,\"OMCL\" ,\"SRPT\" ,\"MEDP\" ,\"PRGO\" ,\"ACHC\" ,\"SGFY\" ,\"HQY\" ,\"NVTA\" ,\"ONEM\" ,\"NVRO\" ,\"VIR\" ,\"SEM\" ,\"IONS\" ,\"ALLK\" ,\"BPMC\" ,\"INSP\" ,\"TWST\" ,\"NEOG\" ,\"ADPT\" ,\"SWAV\" ,\"GLPG\" ,\"ALHC\" ,\"APHA\" ,\"INOV\" ,\"MPLN\" ,\"OCDX\" ,\"PACB\" ,\"NARI\" ,\"SDGR\" ,\"ABCM\" ,\"ENSG\" ,\"OSCR\" ,\"QDEL\" ,\"PGNY\" ,\"CERT\" ,\"ICUI\" ,\"PINC\" ,\"BHVN\" ,\"AMN\" ,\"BEAM\" ,\"ALLO\" ,\"CVET\" ,\"CNMD\" ,\"LIVN\" ,\"HCM\" ,\"INNV\" ,\"AGIO\" ,\"CMD\" ,\"GKOS\" ,\"APLS\" ,\"ARNA\" ,\"MMSI\" ,\"LEGN\" ,\"NUVA\" ,\"PDCO\" ,\"ALKS\" ,\"SWTX\" ,\"ACAD\" ,\"CLOV\" ,\"NKTR\" ,\"INSM\" ,\"EBS\" ,\"AMWL\" ,\"SDC\" ,\"OPCH\" ,\"HAE\" ,\"TPTX\" ,\"SANA\" ,\"ITGR\" ,\"BLI\" ,\"SGRY\" ,\"ARVN\" ,\"MOR\" ,\"INMD\" ,\"TARO\" ,\"PTCT\" ,\"PCRX\" ,\"OPK\" ,\"ITCI\" ,\"BFLY\" ,\"TIL\" ,\"MDRX\" ,\"OMI\" ,\"SEER\" ,\"MGLN\" ,\"GBT\" ,\"PBH\" ,\"ALXO\" ,\"MD\" ,\"ACCD\" ,\"BCRX\" ,\"TLRY\" ,\"AXNX\" ,\"HCSG\" ,\"HCAT\" ,\"OM\" ,\"IRTC\" ,\"EDIT\" ,\"PHR\" ,\"RVMD\" ,\"AVNS\" ,\"RUBY\" ,\"MYGN\" ,\"MCRB\" ,\"DRNA\" ,\"MODV\" ,\"DCPH\" ,\"NGM\" ,\"BLUE\" ,\"MDGL\" ,\"RCUS\" ,\"CCXI\" ,\"PRLD\" ,\"FGEN\" ,\"IGMS\" ,\"AVIR\" ,\"MGNX\" ,\"GBIO\" ,\"MYOV\" ,\"SILK\" ,\"ADCT\" ,\"LMNX\" ,\"IRWD\" ,\"IMCR\" ,\"CYH\" ,\"EVH\" ,\"ACB\" ,\"CYTK\" ,\"KURA\" ,\"REPL\" ,\"EAR\" ,\"IMVT\" ,\"ARQT\" ,\"PMVP\" ,\"CSII\" ,\"AMTI\" ,\"DSGN\" ,\"USPH\" ,\"LUNG\" ,\"ADUS\" ,\"SGMO\" ,\"RGNX\" ,\"QURE\" ,\"NFH\" ,\"INGN\" ,\"EWTX\" ,\"CCCC\" ,\"KRON\" ,\"TBIO\" ,\"ALVR\" ,\"IMGN\" ,\"PGEN\" ,\"ZYME\" ,\"ALEC\" ,\"STTK\" ,\"INO\" ,\"ZEAL\" ,\"CDXS\" ,\"PETQ\" ,\"CGEM\" ,\"ENDP\" ,\"CRY\" ,\"CMPS\" ,\"NXGN\" ,\"NRC\" ,\"BKD\" ,\"ACRS\" ,\"ATEC\" ,\"TVTY\" ,\"RPTX\" ,\"INVA\" ,\"YMAB\" ,\"STOK\" ,\"PLRX\" ,\"ATRI\" ,\"PNTG\" ,\"CRTX\" ,\"SNDL\" ,\"ATRA\" ,\"PRAX\" ,\"ALGS\" ,\"KNTE\" ,\"ENTA\" ,\"MRSN\" ,\"CNST\" ,\"SRRK\" ,\"KNSA\" ,\"HNGR\" ,\"RAD\" ,\"APR\" ,\"VREX\" ,\"PHAT\" ,\"PRTA\" ,\"BDTX\" ,\"AKRO\" ,\"ANGO\" ,\"FDMT\" ,\"RXDX\" ,\"PCVX\" ,\"VOR\" ,\"PASG\" ,\"NTUS\" ,\"AMPH\" ,\"AMRX\" ,\"ORIC\" ,\"OLMA\" ,\"OFIX\" ,\"NKTX\" ,\"HEXO\" ,\"HSTM\" ,\"VIVO\" ,\"TSHA\" ,\"DYN\" ,\"BOLT\" ,\"PHVS\" ,\"BVS\" ,\"MESO\" ,\"TCRR\" ,\"GRCL\" ,\"COLL\" ,\"ADAP\" ,\"ANNX\" ,\"SRDX\" ,\"GTHX\" ,\"RFL\" ,\"VYNE\" ,\"KDNY\" ,\"SNDX\" ,\"HARP\" ,\"ANAB\" ,\"OSUR\" ,\"EPZM\" ,\"CALT\" ,\"BCYC\" ,\"ATHA\" ,\"DBVT\" ,\"ACHL\" ,\"ZIOP\" ,\"ORTX\" ,\"GOSS\" ,\"LXRX\" ,\"ISEE\" ,\"KDMN\" ,\"CO\" ,\"PETS\" ,\"FNCH\" ,\"IDYA\" ,\"SPNE\" ,\"RLMD\" ,\"KPTI\" ,\"GTS\" ,\"CLVS\" ,\"MGTX\" ,\"TARS\" ,\"ANIK\" ,\"TLMD\" ,\"OGI\" ,\"ICPT\" ,\"RIGL\" ,\"CRNX\" ,\"CUTR\" ,\"PSTX\" ,\"CTMX\" ,\"XBIT\" ,\"NBTX\" ,\"EVLO\" ,\"VAPO\" ,\"DTIL\" ,\"OYST\" ,\"HOOK\" ,\"AKUS\" ,\"ANGN\" ,\"CPSI\" ,\"PRVB\" ,\"SPPI\" ,\"MTEM\" ,\"AMYT\" ,\"ARAY\" ,\"GERN\" ,\"SGTX\" ,\"ATNX\" ,\"GRTS\" ,\"VIRX\" ,\"SLDB\" ,\"SIEN\" ,\"TERN\" ,\"PBYI\" ,\"INZY\" ,\"OPT\" ,\"TXMD\" ,\"FUSN\" ,\"AVRO\" ,\"SPRB\" ,\"BCEL\" ,\"SPRO\" ,\"FREQ\" ,\"FLDM\" ,\"AFIB\" ,\"IPHA\" ,\"BDSI\" ,\"APYX\" ,\"UTMD\" ,\"JNCE\" ,\"ORPH\" ,\"SYRS\" ,\"FRLN\" ,\"KLDO\" ,\"LVTX\" ,\"KALA\" ,\"BLU\" ,\"SQZ\" ,\"CSLT\" ,\"FIXX\" ,\"KMDA\" ,\"CBAY\" ,\"NH\" ,\"IVC\" ,\"AUTL\" ,\"COGT\" ,\"KZR\" ,\"IMUX\" ,\"UBX\" ,\"ABUS\" ,\"CHMA\" ,\"CABA\" ,\"OVID\" ,\"NXTC\" ,\"NUVB\" ,\"TCDA\" ,\"LHDX\" ,\"INFI\" ,\"OSMT\" ,\"LCI\" ,\"SRGA\" ,\"NCNA\" ,\"DBTX\" ,\"GNFT\" ,\"OBSV\" ,\"XERS\" ,\"MIST\" ,\"VYGR\" ,\"OPTN\" ,\"SBBP\" ,\"SCPH\" ,\"ERYP\" ,\"CCM\" ,\"CALA\" ,\"SIOX\" ,\"GLTO\" ,\"ENZ\" ,\"ASMB\" ,\"IMRA\" ,\"ODT\" ,\"OTIC\" ,\"IFRX\" ,\"CSU\" ,\"APRE\" ,\"SVRA\" ,\"APTX\" ,\"CYCN\" ,\"ARAV\" ,\"ECOR\" ,\"GEG\" ,\"TRIB\" ,\"ALNA\" ,\"ACOR\" ,\"CPIX\" ,\"NBRV\" ,\"TLGT\" ,\"PTIX\" ,\"AGTI\" ,\"HOWL\" ,\"AVAH\" ,\"VACC\" ,\"BDXB\" ,\"AKYA\" ,\"CHNGU\" ,\"PALI\" ,\"AGL\" ,\"DHR-PB\" ,\"BSX-PA\" ,\"BMEA\" ,\"RAIN\" ,\"TMCI\" ,\"RXRX\" ,\"ELAT\" ,\"NUWE\" ,\"VECT\" ,\"PRVA\"]\n",
    "len(health_tickers)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-05-06T20:51:47.078474Z",
     "iopub.status.busy": "2021-05-06T20:51:47.078255Z",
     "iopub.status.idle": "2021-05-06T20:51:47.089889Z",
     "shell.execute_reply": "2021-05-06T20:51:47.088769Z",
     "shell.execute_reply.started": "2021-05-06T20:51:47.078452Z"
    }
   },
   "outputs": [],
   "source": [
    "energy_tickers = [\"XOM\" ,\"CVX\" ,\"RDS-A\" ,\"RDS-B\" ,\"PTR\" ,\"TOT\" ,\"BP\" ,\"ENB\" ,\"SNP\" ,\"COP\" ,\"EQNR\" ,\"PBR-A\" ,\"PBR\" ,\"EPD\" ,\"TRP\" ,\"EOG\" ,\"E\" ,\"SLB\" ,\"KMI\" ,\"CNQ\" ,\"MPC\" ,\"PSX\" ,\"PXD\" ,\"SU\" ,\"VLO\" ,\"WMB\" ,\"CSAN\" ,\"MPLX\" ,\"HES\" ,\"ET\" ,\"OXY\" ,\"EC\" ,\"BKR\" ,\"OKE\" ,\"HAL\" ,\"PBA\" ,\"DVN\" ,\"CVE\" ,\"TS\" ,\"FANG\" ,\"TPL\" ,\"CLR\" ,\"MMP\" ,\"SSL\" ,\"MRO\" ,\"WES\" ,\"TRGP\" ,\"APA\" ,\"PSXP\" ,\"CCJ\" ,\"XEC\" ,\"PAA\" ,\"COG\" ,\"OVV\" ,\"NOV\" ,\"SHLX\" ,\"VVV\" ,\"HFC\" ,\"SHI\" ,\"DCP\" ,\"EQT\" ,\"CHX\" ,\"NFG\" ,\"CHK\" ,\"AM\" ,\"UGP\" ,\"PDCE\" ,\"FTI\" ,\"SUN\" ,\"ETRN\" ,\"ENBL\" ,\"MTDR\" ,\"SWN\" ,\"HP\" ,\"MGY\" ,\"CNX\" ,\"VNOM\" ,\"RRC\" ,\"DEN\" ,\"MUR\" ,\"AR\" ,\"NS-PB\" ,\"WHD\" ,\"ENLC\" ,\"LBRT\" ,\"REGI\" ,\"CPG\" ,\"CVI\" ,\"RIG\" ,\"CEQP\" ,\"BSM\" ,\"HEP\" ,\"INT\" ,\"NS\" ,\"CRC\" ,\"SM\" ,\"CLNE\" ,\"PBF\" ,\"DK\" ,\"PAGP\" ,\"DKL\" ,\"EURN\" ,\"RTLR\" ,\"CPE\" ,\"OAS\" ,\"WLL\" ,\"FRO\" ,\"PTEN\" ,\"YPF\" ,\"AROC\" ,\"USAC\" ,\"BPMP\" ,\"CLB\" ,\"OII\" ,\"GLOG-PA\" ,\"NBLX\" ,\"CRK\" ,\"TGP\" ,\"ERF\" ,\"DNOW\" ,\"DRQ\" ,\"VET\" ,\"GLNG\" ,\"RES\" ,\"KOS\" ,\"GEL\" ,\"XOG\" ,\"PUMP\" ,\"STNG\" ,\"NGL-PB\" ,\"NGL-PC\" ,\"VEI\" ,\"TALO\" ,\"DHT\" ,\"MNRL\" ,\"PBFX\" ,\"GPRK\" ,\"GLOP-PC\" ,\"GLOP-PB\" ,\"MRC\" ,\"GLP\" ,\"NEX\" ,\"VTOL\" ,\"FI\" ,\"SLCA\" ,\"BOOM\" ,\"PARR\" ,\"BCEI\" ,\"OMP\" ,\"ARCH\" ,\"CAPL\" ,\"ARLP\" ,\"HLX\" ,\"KRP\" ,\"ESTE\" ,\"LPG\" ,\"NBR\" ,\"TRMD\" ,\"TGS\" ,\"FLNG\" ,\"WTTR\" ,\"NVGS\" ,\"PVAC\" ,\"TDW\" ,\"GLOG\" ,\"HMLP\" ,\"SRLP\" ,\"NBR-PA\" ,\"DMLP\" ,\"SBR\" ,\"CLMT\" ,\"REX\" ,\"BRY\" ,\"WTI\" ,\"TNK\" ,\"SOI\" ,\"BTU\" ,\"DSSI\" ,\"SGU\" ,\"LPI\" ,\"CEIX\" ,\"TTI\" ,\"NOA\" ,\"HESM\" ,\"OIS\" ,\"PDS\" ,\"TK\" ,\"TNP-PD\" ,\"TNP-PE\" ,\"NR\" ,\"TNP-PF\" ,\"NGL\" ,\"BORR\" ,\"AMR\" ,\"SJT\" ,\"NRP\" ,\"VIST\" ,\"OSG\" ,\"RNET\" ,\"TNP\" ,\"PBT\" ,\"NC\" ,\"TUSK\" ,\"GLOP\" ,\"SD\" ,\"EGY\" ,\"SLNG\" ,\"EXTN\" ,\"SBOW\" ,\"NGS\" ,\"FTK\" ,\"AMPY\" ,\"GEOS\" ,\"FET\" ,\"SND\" ,\"DLNG\" ,\"KLXE\" ,\"RNGR\" ,\"SMLP\" ,\"MMLP\" ,\"DLNG-PB\" ,\"BPT\" ,\"CCLP\" ,\"PRT\" ,\"PHX\" ,\"GIFI\" ,\"MVO\" ,\"NINE\" ,\"VOC\" ,\"CRT\" ,\"NRT\" ,\"DWSN\" ,\"NNA\" ,\"PVL\" ,\"IO\" ,\"CELP\" ,\"ICD\" ,\"MARPS\" ,\"MTR\" ,\"DCP-PB\" ,\"TGP-PA\" ,\"NS-PC\" ,\"ALIN-PA\" ,\"ALIN-PE\" ,\"EP-PC\" ,\"GLOP-PA\" ,\"CEQP-P\" ,\"HMLP-PA\" ,\"ALIN-PB\" ,\"DCP-PC\" ,\"NS-PA\" ,\"VAL\" ,\"TGP-PB\" ,\"DLNG-PA\" ,\"GLP-PB\" ,\"GLP-PA\" ,\"GMLPP\" ,\"UROY\"]\n",
    "len(energy_tickers)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "amzn.recommendations.tail(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-05-06T20:57:48.251353Z",
     "iopub.status.busy": "2021-05-06T20:57:48.251115Z",
     "iopub.status.idle": "2021-05-06T20:57:48.256915Z",
     "shell.execute_reply": "2021-05-06T20:57:48.254900Z",
     "shell.execute_reply.started": "2021-05-06T20:57:48.251329Z"
    }
   },
   "outputs": [],
   "source": [
    "amzn.session"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-05-08T22:07:58.908224Z",
     "iopub.status.busy": "2021-05-08T22:07:58.907974Z",
     "iopub.status.idle": "2021-05-08T22:07:58.913753Z",
     "shell.execute_reply": "2021-05-08T22:07:58.912352Z",
     "shell.execute_reply.started": "2021-05-08T22:07:58.908200Z"
    }
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Sentiment Analysis:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-05-11T20:08:01.682207Z",
     "iopub.status.busy": "2021-05-11T20:08:01.681882Z",
     "iopub.status.idle": "2021-05-11T20:08:02.262289Z",
     "shell.execute_reply": "2021-05-11T20:08:02.261502Z",
     "shell.execute_reply.started": "2021-05-11T20:08:01.682167Z"
    }
   },
   "outputs": [],
   "source": [
    "# https://codingandfun.com/company-earnings-sentiment-analysis-with-python/\n",
    "from textblob import TextBlob\n",
    "import numpy as np\n",
    "import requests\n",
    "import pandas as pd\n",
    "import nltk"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import nltk\n",
    "from nltk.tokenize import RegexpTokenizer\n",
    "from nltk.corpus import stopwords\n",
    "nltk.download('stopwords')\n",
    "\n",
    "my_stopwords = nltk.corpus.stopwords.words('english')\n",
    "word_rooter = nltk.stem.snowball.PorterStemmer(ignore_stopwords=False).stem\n",
    "my_punctuation = '!\"$%&\\'()*+,-./:;<=>?[\\\\]^_`{|}~•@'\n",
    "\n",
    "# cleaning master function\n",
    "def clean_call(call, bigrams=False):\n",
    "    call = call.lower() # lower case\n",
    "    call = re.sub('['+my_punctuation + ']+', ' ', call) # strip punctuation\n",
    "    call = re.sub('\\s+', ' ', call) #remove double spacing\n",
    "    call = re.sub('([0-9]+)', '', call) # remove numbers\n",
    "    #call_token_list = [word for word in call.split(' ')\n",
    "    #                        if word not in my_stopwords] # remove stopwords\n",
    "    #call_token_list = [word_rooter(word) if '#' not in word else word\n",
    "    #                    for word in call_token_list] # apply word rooter\n",
    "    \n",
    "    call_token_list = [word_rooter(word) if '#' not in word else word\n",
    "                        for word in call.split(' ')] # modify word rooter to skip stop word removal\n",
    "    \n",
    "    if bigrams:\n",
    "        call_token_list = call_token_list+[call_token_list[i]+'_'+call_token_list[i+1]\n",
    "                                            for i in range(len(call_token_list)-1)]\n",
    "    call = ' '.join(call_token_list)\n",
    "    return call"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-05-11T20:09:27.543725Z",
     "iopub.status.busy": "2021-05-11T20:09:27.543503Z",
     "iopub.status.idle": "2021-05-11T20:09:27.549054Z",
     "shell.execute_reply": "2021-05-11T20:09:27.547678Z",
     "shell.execute_reply.started": "2021-05-11T20:09:27.543702Z"
    }
   },
   "outputs": [],
   "source": [
    "sentiment_polarity = []\n",
    "sentiment_subjectivity = []\n",
    "ID = []\n",
    "\n",
    "for sector in ['energy', 'health', 'tech']:\n",
    "    # Quarterly call transcripts are saved in \"directory\"\n",
    "    directory = r'/Users/pgoff/Google Drive/1_Learning_Python/Goff_Repo/Classification/' + sector + '_transcripts'\n",
    "    transcripts = [trans for trans in os.listdir(directory) if (trans.find(\".txt\") + 1)]\n",
    "\n",
    "    for file in transcripts:\n",
    "        path = './' + sector + '_transcripts/' + file \n",
    "        with open(path, 'r') as file:\n",
    "            BagOfWords = file.read().replace('\\n', '')\n",
    "            BagOfWords = clean_call(BagOfWords)\n",
    "            sentiment_call = TextBlob(BagOfWords)\n",
    "            sentiment_polarity.append(sentiment_call.sentiment[0])\n",
    "            sentiment_subjectivity.append(sentiment_call.sentiment[1])     \n",
    "            ID.append(fname[:-4])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-05-12T21:56:46.243237Z",
     "iopub.status.busy": "2021-05-12T21:56:46.242892Z",
     "iopub.status.idle": "2021-05-12T21:56:46.251086Z",
     "shell.execute_reply": "2021-05-12T21:56:46.249763Z",
     "shell.execute_reply.started": "2021-05-12T21:56:46.243183Z"
    }
   },
   "outputs": [],
   "source": [
    "sentiment_polarity = []\n",
    "sentiment_subjectivity = []\n",
    "ID = []\n",
    "\n",
    "#for sector in ['energy', 'health', 'tech']:\n",
    "sector = 'tech'\n",
    "# Quarterly call transcripts are saved in \"directory\"\n",
    "directory = r'/Users/pgoff/Google Drive/1_Learning_Python/Goff_Repo/Classification/' + sector + '_transcripts'\n",
    "transcripts = [trans for trans in os.listdir(directory) if (trans.find(\".txt\") + 1)\n",
    "file = transcripts[0]\n",
    "#for file in transcripts:\n",
    "path = './' + sector + '_transcripts/' + file \n",
    "with open(path, 'r') as file:\n",
    "    BagOfWords = file.read().replace('\\n', '')\n",
    "    BagOfWords = clean_call(BagOfWords)\n",
    "    sentiment_call = TextBlob(BagOfWords)\n",
    "    sentiment_polarity.append = sentiment_call.sentiment[0]\n",
    "    sentiment_subjectivity.append = sentiment_call.sentiment[1]      \n",
    "    ID.append = file[:-4]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sentiment_call = TextBlob(transcript)\n",
    "print(sentiment_call.sentiment)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-05-10T13:46:02.365386Z",
     "iopub.status.busy": "2021-05-10T13:46:02.365171Z",
     "iopub.status.idle": "2021-05-10T13:46:02.368437Z",
     "shell.execute_reply": "2021-05-10T13:46:02.367368Z",
     "shell.execute_reply.started": "2021-05-10T13:46:02.365363Z"
    }
   },
   "outputs": [],
   "source": [
    "# Topic Modeling\n",
    "https://www.researchgate.net/publication/325647424_Varimax_Rotation_and_Thereafter_Tutorial_on_PCA_Using_Linear_Algebra_Visualization_and_Python_Programming_for_R_and_Q_analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import random\n",
    "import matplotlib_pyplot as plt\n",
    "df = pd_read_csv(filepath) # construct pandas dataset - document by term.\n",
    "labels = df[\"ticker_quarter_year\"J\n",
    "            \n",
    "# Looks like we can use a pca package and then use varimax from factor_analyzer for the rotation\n",
    "# https://factor-analyzer.readthedocs.io/en/latest/index.html\n",
    "!pip install factor_analyzer\n",
    "            "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# What PCA to use? \n",
    "# sparse PCA?  \n",
    "# https://scikit-learn.org/stable/modules/generated/sklearn.decomposition.SparsePCA.html?highlight=pca#sklearn.decomposition.SparsePCA\n",
    "# IncrementalPCA may be helpful if memory is an issue https://scikit-learn.org/stable/modules/generated/sklearn.decomposition.IncrementalPCA.html?highlight=pca#sklearn.decomposition.IncrementalPCA\n",
    "\n",
    "https://scikit-learn.org/stable/modules/decomposition.html#kernel-pca\n",
    "\n",
    "[TruncatedSVD](https://scikit-learn.org/stable/modules/generated/sklearn.decomposition.TruncatedSVD.html#sklearn.decomposition.TruncatedSVD) implements a variant of singular value decomposition (SVD) that only computes the k largest singular values, where k is a user-specified parameter.\n",
    "When truncated SVD is applied to term-document matrices (as returned by CountVectorizer or TfidfVectorizer), this transformation is known as latent semantic analysis (LSA), because it transforms such matrices to a “semantic” space of low dimensionality. In particular, LSA is known to combat the effects of synonymy and polysemy (both of which roughly mean there are multiple meanings per word), which cause term-document matrices to be overly sparse and exhibit poor similarity under measures such as cosine similarity.       "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:metis]",
   "language": "python",
   "name": "conda-env-metis-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
